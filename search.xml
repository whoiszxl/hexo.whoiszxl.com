<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Git工作中使用与常用命令</title>
    <url>/2020/03/21/4.work/Git%E5%B7%A5%E4%BD%9C%E4%B8%AD%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h3 id="Git工作基础流程"><a href="#Git工作基础流程" class="headerlink" title="Git工作基础流程"></a>Git工作基础流程</h3><ol>
<li><code>git clone git_address</code> 在本地机器上克隆代码到本地机器 </li>
<li><code>git add .</code> 修改代码，然后将代码添加到暂存区</li>
<li><code>git commit -m &quot;代码备注&quot;</code> 提交代码到仓库区</li>
<li><code>git pull</code> 拉取远程仓库最新的代码到本地</li>
<li><code>再次add与commit</code> 存在冲突的话需要解决冲突</li>
<li><code>git push origin branch</code> 提交代码到远程仓库</li>
</ol>
<span id="more"></span>

<h3 id="Git工作具体使用"><a href="#Git工作具体使用" class="headerlink" title="Git工作具体使用"></a>Git工作具体使用</h3><blockquote>
<p>模拟员工新入职的角度描述在工作中需要使用的Git</p>
</blockquote>
<h4 id="1-新入职后熟悉代码"><a href="#1-新入职后熟悉代码" class="headerlink" title="1. 新入职后熟悉代码"></a>1. 新入职后熟悉代码</h4><p>员工入职后，一般会通过运维给开通一个内网Gitlab的账号，通过内网地址和账号密码可以登录到Gitlab界面，此时我们需要通过将代码拷贝到本地来熟悉代码，步骤是先用自己的机器生成密钥配置到gitlab中，以此达到在本地免密操作远程代码，然后再克隆代码到本地，命令如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成密钥,输入命令一直回车到最后,会输出一个id_rsa.pub的文件目录，复制此文件内容到gitlab-&gt;setting-&gt;sshkeys中</span></span><br><span class="line">ssh-keygen.exe -t rsa</span><br><span class="line"></span><br><span class="line"><span class="comment"># 克隆代码到本地</span></span><br><span class="line">git <span class="built_in">clone</span> git@github.com:whoiszxl/KillerQueen.git</span><br></pre></td></tr></table></figure>


<p>克隆代码到本地后就能愉快的写代码了</p>
<h4 id="2-配置Git"><a href="#2-配置Git" class="headerlink" title="2. 配置Git"></a>2. 配置Git</h4><p>使用Git上传代码的时候，需要附带上当前操作者的信息，所以需要配置一下信息</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看当前的git配置</span></span><br><span class="line">git config --list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置git的用户和邮箱，可以全局配置，也可以在项目目录下单独配置</span></span><br><span class="line">git config [--global] user.name <span class="string">&quot;your name&quot;</span></span><br><span class="line">git config [--global] user.email <span class="string">&quot;your email&quot;</span></span><br></pre></td></tr></table></figure>


<h4 id="3-切换开发分支"><a href="#3-切换开发分支" class="headerlink" title="3. 切换开发分支"></a>3. 切换开发分支</h4><p>在开发的时候，通常是多个人进行合作开发，同时在一个分支下开发的话有可能会出现代码冲突，或者多个环境下开发需要多套代码，所以分支就很有必要了</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看分支</span></span><br><span class="line">git branch [-r 查看所有远程分支] [-a 查看所有本地和远程分支]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建分支并切换到该分支</span></span><br><span class="line">git checkout -b branch-name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并分支</span></span><br><span class="line">git merge branch-name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除本地分支</span></span><br><span class="line">git branch -d branch-name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除远程分支</span></span><br><span class="line">git push origin --delete remote-branch-name</span><br></pre></td></tr></table></figure>


<h4 id="4-开发中增删文件"><a href="#4-开发中增删文件" class="headerlink" title="4. 开发中增删文件"></a>4. 开发中增删文件</h4><p>在开发中能从暂存区增加和删除文件,添加到暂存区的好处是在写错代码的时候可以回到上次add的节点</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加指定文件或文件夹</span></span><br><span class="line">git add [file1] [dir2] ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加所有改动文件到暂存区（常用）</span></span><br><span class="line">git add . </span><br><span class="line"></span><br><span class="line"><span class="comment"># 同时删除工作区和暂存区的指定文件或文件夹</span></span><br><span class="line">git rm [file1] [dir2] ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 只删除暂存区的指定文件(有时候修改了多个文件，有一个文件不想add却不小心add了，用这个解决)</span></span><br><span class="line">git rm --cached [file1] [dir2] ...</span><br></pre></td></tr></table></figure>

<h4 id="5-开发中提交代码到仓库中"><a href="#5-开发中提交代码到仓库中" class="headerlink" title="5. 开发中提交代码到仓库中"></a>5. 开发中提交代码到仓库中</h4><p>在开发中添加到暂存区的代码需要提交到仓库中，形成一个commit记录，以后就可以直接通过commit管理每个提交节点的功能代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 提交暂存区代码到仓库中</span></span><br><span class="line">git commit -m <span class="string">&quot;备注信息&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交暂存区指定代码到仓库中</span></span><br><span class="line">git commit [fileOrDir] -m <span class="string">&quot;备注信息&quot;</span></span><br></pre></td></tr></table></figure>

<h5 id="6-打Tag标记"><a href="#6-打Tag标记" class="headerlink" title="6. 打Tag标记"></a>6. 打Tag标记</h5><p>作用是给commit指向一个tag，给分支做标记，比如说开发了一个重大功能，可以标记一个版本号</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加一个标记并添加备注</span></span><br><span class="line">git tag -a tag-name -m <span class="string">&quot;tag备注&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加一个标记到指定commit</span></span><br><span class="line">git tag tag-name commit_id</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交标签到远程仓库</span></span><br><span class="line">git push origin tag-name [--tags 换成这个可以添加本地所有tag到远程仓库]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交所有tags</span></span><br><span class="line">git push origin --tags</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个分支并指向一个tag</span></span><br><span class="line">git checkout -b branch-name tag-name</span><br></pre></td></tr></table></figure>


<h5 id="7-查看代码修改的记录"><a href="#7-查看代码修改的记录" class="headerlink" title="7. 查看代码修改的记录"></a>7. 查看代码修改的记录</h5><p>查看记录的话用命令行查看比较不方便，可以使用SourceTree，SublimeMerge,VsCode Git插件等图形工具，可以详细查看到代码的修改提交记录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一些基础命令</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看提交历史</span></span><br><span class="line">git <span class="built_in">log</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看暂存区和工作区的差异</span></span><br><span class="line">git diff</span><br></pre></td></tr></table></figure>

<h5 id="8-撤销代码"><a href="#8-撤销代码" class="headerlink" title="8. 撤销代码"></a>8. 撤销代码</h5><p>写错代码了，想重写，便可以试着撤销代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 代码未添加到暂存区，可以使用此命令放弃所有文件修改</span></span><br><span class="line">git checkout .</span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码未添加到暂存区，可以使用此命令放弃单个文件修改</span></span><br><span class="line">git checkout -- fileOrDirName</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码已添加到暂存区如何撤销</span></span><br><span class="line">git reset HEAD . <span class="comment"># 清除暂存区的文件修改缓存，此时本地修改还未改变</span></span><br><span class="line">git checkout . <span class="comment"># 再次执行checkout可以撤销</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码已经commit添加到仓库</span></span><br><span class="line">git reset --hard HEAD^ <span class="comment">#回退到上一个commit的状态</span></span><br><span class="line">git reset --hard commit_id <span class="comment">#回退到指定的commit版本</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>其他</category>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
      </tags>
  </entry>
  <entry>
    <title>Rust光速入门</title>
    <url>/2021/07/01/6.rust/Rust%E5%85%89%E9%80%9F%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Rust</category>
      </categories>
      <tags>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker+Kubernates云原生</title>
    <url>/2021/12/01/7.cloud/Docker+Kubernates%E4%BA%91%E5%8E%9F%E7%94%9F/</url>
    <content><![CDATA[<h2 id="云原生的概念"><a href="#云原生的概念" class="headerlink" title="云原生的概念"></a>云原生的概念</h2><p>云计算是什么：云计算是一种新的互联网模式，云厂商可以出租公私有云给我们，我们可以极其便捷的<strong>随时获取，按需使用，随时扩展，按使用付费</strong>，就像使用水电一样简单，而不必像以前一样需要自己购买物理机，搭建机房等复杂操作。</p>
<p>云平台优点：</p>
<ol>
<li>稳定，云厂商运维稳定，分布式集群部署简单，高可用</li>
<li>弹性扩展，可以根据项目的负载压力动态选择机器配置</li>
<li>安全性高，权限系统完善，比如安全组等。</li>
<li>成本低，比自建机房的成本低</li>
<li>便于使用，有成熟的web界面操作运维</li>
</ol>
<p>云平台缺点：</p>
<ol>
<li>敏感信息安全性：安全级别很高的数据托管在第三方存在风险</li>
</ol>
<p>上云的挑战：<br>云机器的资源编排，云存储，负载均衡，缓存，云持久化，云运维，云监控，云容器，云devops，云安全防护等</p>
<p>云原生常用技术：<br>Docker、Docker Compose：容器化技术<br>Kubernetes：大规模容器编排<br>Helm：云原生应用商店<br>Rancher：易用的容器管理平台<br>KubeSphere：一站式容器云平台<br>OpenTracing：云原生链路追踪标准<br>Jaeger：云原生链路追踪实现产品<br>Istio：ServiceMesh下的服务流量治理<br>Jenkins、JenkinsX、Jenkins-BlueOcean：老牌的CI/CD平台<br>Gitlab/hub-CICD：Gitlab/hub自带的CICD<br>Argo：kubernetes声明式持续集成<br>Nexus：Maven私库<br>Habor：Docker私库<br>Prometheus+Grafana：监控与可视化方案<br>ElasticSearch+Fluentd+Kibana：日志与可视化方案<br>Serverless：无服务器上云方案<br>SpringCloud Kubernetes：微服务上云方案</p>
<h2 id="Docker基础使用"><a href="#Docker基础使用" class="headerlink" title="Docker基础使用"></a>Docker基础使用</h2>]]></content>
      <categories>
        <category>运维</category>
        <category>云原生</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>云原生</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring从零到深入笔记</title>
    <url>/2021/12/01/1.java/spring/Spring%E4%BB%8E%E9%9B%B6%E5%88%B0%E6%B7%B1%E5%85%A5%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>CDH各大组件安装</title>
    <url>/2021/06/01/2.bigdata/build/CDH%E5%90%84%E5%A4%A7%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<p>上一步安装好了CM后，我们就可以进CM管理后台进行添加服务，安装组件的操作了</p>
<h2 id="添加其他服务器"><a href="#添加其他服务器" class="headerlink" title="添加其他服务器"></a>添加其他服务器</h2><h3 id="1-进入到All-Host界面下"><a href="#1-进入到All-Host界面下" class="headerlink" title="1.进入到All Host界面下"></a>1.进入到All Host界面下</h3><p>此时列表下只有hadoop001这台机器，点击Add Hosts来新增其他机器</p>
<span id="more"></span>
<p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_1.png"></p>
<h3 id="2-选择添加hosts到我们选定的集群里"><a href="#2-选择添加hosts到我们选定的集群里" class="headerlink" title="2.选择添加hosts到我们选定的集群里"></a>2.选择添加hosts到我们选定的集群里</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_2.png"></p>
<h3 id="3-直接搜索出其他两台机器并选中添加"><a href="#3-直接搜索出其他两台机器并选中添加" class="headerlink" title="3.直接搜索出其他两台机器并选中添加"></a>3.直接搜索出其他两台机器并选中添加</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_3.png"></p>
<h3 id="4-选择自定义本地仓库"><a href="#4-选择自定义本地仓库" class="headerlink" title="4.选择自定义本地仓库"></a>4.选择自定义本地仓库</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_4.png"></p>
<h3 id="5-选择安装Oracle的JDK"><a href="#5-选择安装Oracle的JDK" class="headerlink" title="5.选择安装Oracle的JDK"></a>5.选择安装Oracle的JDK</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_5.png"></p>
<h3 id="6-配置root的密码"><a href="#6-配置root的密码" class="headerlink" title="6.配置root的密码"></a>6.配置root的密码</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_6.png"></p>
<h3 id="7-等待agents安装成功"><a href="#7-等待agents安装成功" class="headerlink" title="7.等待agents安装成功"></a>7.等待agents安装成功</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_7.png"></p>
<h3 id="8-等待包的下载，分发，解压与激活"><a href="#8-等待包的下载，分发，解压与激活" class="headerlink" title="8.等待包的下载，分发，解压与激活"></a>8.等待包的下载，分发，解压与激活</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_8.png"></p>
<h3 id="9-检查主机"><a href="#9-检查主机" class="headerlink" title="9.检查主机"></a>9.检查主机</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_9.png"></p>
<h3 id="10-选择host模板，默认就好了"><a href="#10-选择host模板，默认就好了" class="headerlink" title="10.选择host模板，默认就好了"></a>10.选择host模板，默认就好了</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_10.png"></p>
<h3 id="11-命令部署客户端配置有问题，直接忽略这个问题就好了"><a href="#11-命令部署客户端配置有问题，直接忽略这个问题就好了" class="headerlink" title="11.命令部署客户端配置有问题，直接忽略这个问题就好了"></a>11.命令部署客户端配置有问题，直接忽略这个问题就好了</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_11.png"></p>
<h2 id="Cloudera-Management-Service安装"><a href="#Cloudera-Management-Service安装" class="headerlink" title="Cloudera Management Service安装"></a>Cloudera Management Service安装</h2><h3 id="1-进入hadoop001-7180-cmf-home下，点击Add按钮下的Add-Cloudera-Management-Service"><a href="#1-进入hadoop001-7180-cmf-home下，点击Add按钮下的Add-Cloudera-Management-Service" class="headerlink" title="1.进入hadoop001:7180/cmf/home下，点击Add按钮下的Add Cloudera Management Service"></a>1.进入hadoop001:7180/cmf/home下，点击Add按钮下的Add Cloudera Management Service</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_12.png"></p>
<h3 id="2-选择监控服务安装在哪台机器上，可以按机器的实际情况去调配"><a href="#2-选择监控服务安装在哪台机器上，可以按机器的实际情况去调配" class="headerlink" title="2.选择监控服务安装在哪台机器上，可以按机器的实际情况去调配"></a>2.选择监控服务安装在哪台机器上，可以按机器的实际情况去调配</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_13.png"></p>
<h3 id="3-配置邮箱预警，配置监控器的本地存储目录"><a href="#3-配置邮箱预警，配置监控器的本地存储目录" class="headerlink" title="3.配置邮箱预警，配置监控器的本地存储目录"></a>3.配置邮箱预警，配置监控器的本地存储目录</h3><p>配置本地存储目录需要创建文件夹并赋予权限</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /var/lib/cloudera-host-monitor</span><br><span class="line">mkdir /var/lib/cloudera-service-monitor</span><br><span class="line">chown -R cloudera-scm:cloudera-scm /var/lib/cloudera-host-monitor</span><br><span class="line">chown -R cloudera-scm:cloudera-scm /var/lib/cloudera-service-monitor/</span><br></pre></td></tr></table></figure>
<p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_14.png"></p>
<h3 id="4-等待安装成功"><a href="#4-等待安装成功" class="headerlink" title="4.等待安装成功"></a>4.等待安装成功</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_15.png"></p>
<h3 id="5-安装成功后，我们在集群状态里就能看到图表的监控在运行了"><a href="#5-安装成功后，我们在集群状态里就能看到图表的监控在运行了" class="headerlink" title="5.安装成功后，我们在集群状态里就能看到图表的监控在运行了"></a>5.安装成功后，我们在集群状态里就能看到图表的监控在运行了</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/add_other_host_16.png"></p>
<h2 id="HDFS安装"><a href="#HDFS安装" class="headerlink" title="HDFS安装"></a>HDFS安装</h2><h3 id="1-进入集群中选择Actions-gt-Add-Service"><a href="#1-进入集群中选择Actions-gt-Add-Service" class="headerlink" title="1.进入集群中选择Actions -&gt; Add Service"></a>1.进入集群中选择Actions -&gt; Add Service</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hdfs_1.png"></p>
<h3 id="2-在列表中选中HDFS"><a href="#2-在列表中选中HDFS" class="headerlink" title="2.在列表中选中HDFS"></a>2.在列表中选中HDFS</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hdfs_2.png"></p>
<h3 id="3-按照机器配置去分配各个组件的安装节点"><a href="#3-按照机器配置去分配各个组件的安装节点" class="headerlink" title="3.按照机器配置去分配各个组件的安装节点"></a>3.按照机器配置去分配各个组件的安装节点</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hdfs_3.png"></p>
<h3 id="4-配置HDFS的基础配置"><a href="#4-配置HDFS的基础配置" class="headerlink" title="4.配置HDFS的基础配置"></a>4.配置HDFS的基础配置</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hdfs_4.png"></p>
<h3 id="5-等待安装成功"><a href="#5-等待安装成功" class="headerlink" title="5.等待安装成功"></a>5.等待安装成功</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hdfs_5.png"></p>
<h3 id="6-安装成功后，在HDFS界面可以看到其相关信息了"><a href="#6-安装成功后，在HDFS界面可以看到其相关信息了" class="headerlink" title="6.安装成功后，在HDFS界面可以看到其相关信息了"></a>6.安装成功后，在HDFS界面可以看到其相关信息了</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hdfs_6.png"></p>
<h3 id="7-关闭权限检查"><a href="#7-关闭权限检查" class="headerlink" title="7.关闭权限检查"></a>7.关闭权限检查</h3><p>HDFS默认能够执行写的用户是hdfs，所以当你在用其他用户角色在Linux上对HDFS有写操作的时候都会被拒绝执行，我们可以在HDFS配置里配置上对应的用户，或者直接关闭dfs的权限检查（dfs.permissions）。</p>
<p>在HDFS界面选择Configuration选项的时候，有时会卡在Loading…界面，此时需要再点击一次右边的Role Groups，再返回配置界面就能加载出来了，不知道是什么情况。</p>
<h3 id="8-安装后测试"><a href="#8-安装后测试" class="headerlink" title="8.安装后测试"></a>8.安装后测试</h3><p>在Shell下执行命令进行测试：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 递归显示目录结构，去除-R为非递归</span></span><br><span class="line">hadoop fs -ls /</span><br><span class="line"></span><br><span class="line"><span class="comment"># 递归创建目录,去除-p为非递归</span></span><br><span class="line">hadoop fs -mkdir -p /<span class="built_in">test</span>/hello</span><br><span class="line"></span><br><span class="line"><span class="comment"># 递归删除目录和文件</span></span><br><span class="line">hadoop fs -rm -R /<span class="built_in">test</span>/hello</span><br></pre></td></tr></table></figure>

<h2 id="Yarn安装"><a href="#Yarn安装" class="headerlink" title="Yarn安装"></a>Yarn安装</h2><h3 id="1-选择Actions-gt-Add-Service-gt-YARN"><a href="#1-选择Actions-gt-Add-Service-gt-YARN" class="headerlink" title="1.选择Actions -&gt; Add Service -&gt; YARN"></a>1.选择Actions -&gt; Add Service -&gt; YARN</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/yarn-1.png"></p>
<h3 id="2-按照机器实际情况分配yarn的组件安装到哪台机器上"><a href="#2-按照机器实际情况分配yarn的组件安装到哪台机器上" class="headerlink" title="2.按照机器实际情况分配yarn的组件安装到哪台机器上"></a>2.按照机器实际情况分配yarn的组件安装到哪台机器上</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/yarn-2.png"></p>
<h3 id="3-等待安装成功，安装成功后便能在主页面看到yarn集群的信息"><a href="#3-等待安装成功，安装成功后便能在主页面看到yarn集群的信息" class="headerlink" title="3.等待安装成功，安装成功后便能在主页面看到yarn集群的信息"></a>3.等待安装成功，安装成功后便能在主页面看到yarn集群的信息</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/yarn-3.png"><br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/yarn-4.png"></p>
<h3 id="4-安装成功后测试yarn是否能正常运行"><a href="#4-安装成功后测试yarn是否能正常运行" class="headerlink" title="4.安装成功后测试yarn是否能正常运行"></a>4.安装成功后测试yarn是否能正常运行</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># π计算</span></span><br><span class="line">yarn jar /opt/cloudera/parcels/CDH/jars/hadoop-mapreduce-examples-3.0.0-cdh6.2.1.jar pi 100 100</span><br><span class="line"></span><br><span class="line"><span class="comment"># wordcount计算</span></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;hello world\nhello zhou\nhello world\nhello hello&quot;</span> &gt;&gt; hello.txt</span><br><span class="line">hadoop fs -put hello.txt /input</span><br><span class="line">yarn jar /opt/cloudera/parcels/CDH/jars/hadoop-mapreduce-examples-3.0.0-cdh6.2.1.jar wordcount /input /output</span><br></pre></td></tr></table></figure>

<h2 id="Zookeeper安装"><a href="#Zookeeper安装" class="headerlink" title="Zookeeper安装"></a>Zookeeper安装</h2><h3 id="1-选择Actions-gt-Add-Service-gt-ZooKepper，分配机器"><a href="#1-选择Actions-gt-Add-Service-gt-ZooKepper，分配机器" class="headerlink" title="1.选择Actions -&gt; Add Service -&gt; ZooKepper，分配机器"></a>1.选择Actions -&gt; Add Service -&gt; ZooKepper，分配机器</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/zk-1.png"></p>
<h3 id="2-配置dataDir快照目录与事务日志目录dataLogDir"><a href="#2-配置dataDir快照目录与事务日志目录dataLogDir" class="headerlink" title="2.配置dataDir快照目录与事务日志目录dataLogDir"></a>2.配置dataDir快照目录与事务日志目录dataLogDir</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/zk-2.png"></p>
<h3 id="3-等待ZooKeeper安装成功，安装成功后便能在主页面看到yarn集群的信息"><a href="#3-等待ZooKeeper安装成功，安装成功后便能在主页面看到yarn集群的信息" class="headerlink" title="3.等待ZooKeeper安装成功，安装成功后便能在主页面看到yarn集群的信息"></a>3.等待ZooKeeper安装成功，安装成功后便能在主页面看到yarn集群的信息</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/zk-3.png"><br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/zk-4.png"></p>
<h3 id="4-测试是否安装成功"><a href="#4-测试是否安装成功" class="headerlink" title="4.测试是否安装成功"></a>4.测试是否安装成功</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入zk命令行</span></span><br><span class="line">zookeeper-client</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行命令</span></span><br><span class="line">create /<span class="built_in">test</span> testvalue</span><br><span class="line">get /<span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<h2 id="Hive安装"><a href="#Hive安装" class="headerlink" title="Hive安装"></a>Hive安装</h2><h3 id="1-选择Actions-gt-Add-Service-gt-Hive，选择依赖，并分配机器"><a href="#1-选择Actions-gt-Add-Service-gt-Hive，选择依赖，并分配机器" class="headerlink" title="1.选择Actions -&gt; Add Service -&gt; Hive，选择依赖，并分配机器"></a>1.选择Actions -&gt; Add Service -&gt; Hive，选择依赖，并分配机器</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hive-1.png"><br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hive-2.png"></p>
<h3 id="2-Hive元数据要配置MySQL数据库，在MySQL中配置对应的数据库信息"><a href="#2-Hive元数据要配置MySQL数据库，在MySQL中配置对应的数据库信息" class="headerlink" title="2.Hive元数据要配置MySQL数据库，在MySQL中配置对应的数据库信息"></a>2.Hive元数据要配置MySQL数据库，在MySQL中配置对应的数据库信息</h3><p>此处连接数据库，需要将MySQL驱动拷贝到Hive的lib目录下</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cp /opt/software/mysql-connector-java-5.1.40.jar /opt/cloudera/parcels/CDH/lib/hive/lib</span><br></pre></td></tr></table></figure>
<p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hive-3.png"></p>
<h3 id="3-配置目录和端口，默认就好了"><a href="#3-配置目录和端口，默认就好了" class="headerlink" title="3.配置目录和端口，默认就好了"></a>3.配置目录和端口，默认就好了</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hive-4.png"></p>
<h3 id="4-等待安装成功-1"><a href="#4-等待安装成功-1" class="headerlink" title="4.等待安装成功"></a>4.等待安装成功</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hive-5.png"></p>
<p>如果没有拷贝MySQL驱动，就会报找不到驱动的错误<br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hive-6.png"></p>
<h3 id="5-安装成功后就可以在主界面看到Hive的信息了"><a href="#5-安装成功后就可以在主界面看到Hive的信息了" class="headerlink" title="5.安装成功后就可以在主界面看到Hive的信息了"></a>5.安装成功后就可以在主界面看到Hive的信息了</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/hive-7.png"></p>
<h3 id="6-测试是否安装成功"><a href="#6-测试是否安装成功" class="headerlink" title="6.测试是否安装成功"></a>6.测试是否安装成功</h3><p>登录Hive命令行客户端</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">hive</span><br></pre></td></tr></table></figure>

<p>执行SQL测试</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> database testdb;</span><br><span class="line">use testdb;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student(id <span class="type">int</span>, name string);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> student <span class="keyword">values</span>(<span class="number">1</span>, <span class="string">&#x27;xiaozhou&#x27;</span>);</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br></pre></td></tr></table></figure>

<h2 id="Oozie安装"><a href="#Oozie安装" class="headerlink" title="Oozie安装"></a>Oozie安装</h2><ol>
<li><p>进入<code>Add Service to Cluster 1</code>界面，选择<code>Oozie</code>，下一步</p>
</li>
<li><p><code>Select Dependencies</code>选择依赖，按需求选择</p>
</li>
<li><p>配置Oozie Server安装到哪台机器，按需求选择</p>
</li>
<li><p>在MySQL中创建Oozie元数据数据库: <code>create database oozie;</code>,然后在配置中填写。</p>
</li>
<li><p>需要拷贝MySQL驱动到oozie的lib目录下才能让oozie连接到MySQL上: </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cp /opt/software/mysql-connector-java-5.1.40.jar /opt/cloudera/parcels/CDH/lib/oozie/lib/</span><br><span class="line">cp /opt/software/mysql-connector-java-5.1.40.jar /var/lib/oozie/</span><br></pre></td></tr></table></figure></li>
<li><p>配置好oozie对应的数据目录</p>
</li>
<li><p>等待安装成功，安装成功后就能在主页面看到oozie的相关信息了。</p>
</li>
</ol>
<h2 id="Impala安装"><a href="#Impala安装" class="headerlink" title="Impala安装"></a>Impala安装</h2><ol>
<li>进入<code>Add Service to Cluster 1</code>界面，选择<code>Impala</code>，下一步</li>
<li>配置Impala组件安装到哪台机器，按需求选择</li>
<li>配置对应的安装目录，等待安装成功就OK了</li>
<li>测试时，输入命令<code>impala-shell</code>进入操作界面，操作和Hive一样就OK了。</li>
</ol>
<h2 id="Kakfa安装"><a href="#Kakfa安装" class="headerlink" title="Kakfa安装"></a>Kakfa安装</h2><ol>
<li>进入<code>Add Service to Cluster 1</code>界面，选择<code>Kafka</code>，下一步</li>
<li>配置三台机器都安装Kafka Broker，其他的选择安装</li>
<li>选择kafka配置，配置<code>Java Heap Size of Broker</code>为1024MiB，推荐是最小512，其他默认</li>
<li>点击完成，等待安装成功，安装成功后需要根据提示进行重启。</li>
<li>下面是Kafka常用命令：<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1.查看当前服务器中的所有topic</span></span><br><span class="line">kafka-topics --zookeeper hadoop001:2181 --list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.创建topic</span></span><br><span class="line"><span class="comment"># --topic 定义topic名</span></span><br><span class="line"><span class="comment"># --replication-factor  定义副本数</span></span><br><span class="line"><span class="comment"># --partitions  定义分区数</span></span><br><span class="line">kafka-topics --zookeeper hadoop002:2181 \</span><br><span class="line">--create --replication-factor 3 --partitions 3 --topic first-topic</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.删除topic (需要server.properties中设置delete.topic.enable=true否则只是标记删除。)</span></span><br><span class="line">kafka-topics --zookeeper hadoop001:2181 \</span><br><span class="line">--delete --topic first-topic</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.发送消息</span></span><br><span class="line">kafka-console-producer --broker-list hadoop001:9092 --topic first-topic</span><br><span class="line">&gt; hello kafka</span><br><span class="line">&gt; hello world</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.消费消息(--from-beginning：会把主题中以往所有的数据都读取出来。)</span></span><br><span class="line">kafka-console-consumer --bootstrap-server hadoop001:9092 --from-beginning --topic first-topic</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.查看某个topic的详情</span></span><br><span class="line">kafka-topics --zookeeper hadoop001:2181 --describe --topic first-topic</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7.修改分区数</span></span><br><span class="line">kafka-topics --zookeeper hadoop001:2181 --alter --topic first-topic --partitions 6</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Sqoop安装"><a href="#Sqoop安装" class="headerlink" title="Sqoop安装"></a>Sqoop安装</h2><ol>
<li>进入<code>Add Service to Cluster 1</code>界面，选择<code>Sqoop 1 Client</code>，下一步</li>
<li>配置选择哪台机器安装就好了，因为Sqoop是客户端类程序，所以是不需长驻内存的。</li>
<li>等待安装成功就OK了</li>
<li>可以输入如下常用命令测试是否能正常使用<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 列出所有db</span></span><br><span class="line">sqoop list-databases --connect jdbc:mysql://hadoop001:3306/ --username root --password 123456</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Spark安装"><a href="#Spark安装" class="headerlink" title="Spark安装"></a>Spark安装</h2><ol>
<li>进入<code>Add Service to Cluster 1</code>界面，选择<code>Spark</code>，下一步</li>
<li>一直下一步安装就好了</li>
<li>在Shell中使用<code>spark-submit</code>命令提交一个求Pi的任务，在<code>http://host001:8088/cluster/</code>可以查看到提交的任务</li>
</ol>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">spark-submit \</span><br><span class="line">--master yarn \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--driver-memory 1024m \</span><br><span class="line">--driver-cores 2 \</span><br><span class="line">--executor-memory 1024m \</span><br><span class="line">--executor-cores 2 \</span><br><span class="line">--num-executors 2 \</span><br><span class="line">--queue default /opt/cloudera/parcels/CDH/jars/spark-examples_2.11-2.4.0-cdh6.2.1.jar 10</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>进入<code>http://host001:8088/cluster/</code>,点击完成的任务，再点击<code>Logs</code>，在最下方就能看到输出的结果：<code>Pi is roughly 3.1404391404391405</code></li>
</ol>
<h2 id="Hue安装"><a href="#Hue安装" class="headerlink" title="Hue安装"></a>Hue安装</h2><ol>
<li>进入<code>Add Service to Cluster 1</code>界面，选择<code>Hue</code>，下一步</li>
<li>配置选择哪台机器安装</li>
<li>创建独立数据库只作为Hue的元数据库</li>
<li>点击下一步就能等待安装成功了，访问：<code>http://hadoop001:8889/hue/accounts/login</code>就能正常使用了</li>
</ol>
]]></content>
      <categories>
        <category>大数据</category>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>环境搭建</tag>
      </tags>
  </entry>
  <entry>
    <title>JUC并发编程深入学习笔记</title>
    <url>/2021/12/01/1.java/concurrent/JUC%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%B7%B1%E5%85%A5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="Java并发理论基础"><a href="#Java并发理论基础" class="headerlink" title="Java并发理论基础"></a>Java并发理论基础</h2><h3 id="1-为什么Java多线程并发很重要"><a href="#1-为什么Java多线程并发很重要" class="headerlink" title="1. 为什么Java多线程并发很重要"></a>1. 为什么Java多线程并发很重要</h3><p>硬件方面：当前摩尔定律（价格不变时，同等大小的集成电路上的元器件个数每隔18-24个月就增加一倍）开始失效，CPU主频不再翻倍，而是采用多核的方式，单核执行效率不再增长，则想要程序处理更快就需要多核并行或并发来编程。</p>
<p>软件方面：互联网企业高并发系统，很多异步、任务等操作需要高效调用，比如说批量调用第三方接口（推送、打标签等），采用多线程并发调用就能大大提升效率。</p>
<h3 id="2-Java底层是什么"><a href="#2-Java底层是什么" class="headerlink" title="2. Java底层是什么"></a>2. Java底层是什么</h3><p>Java底层的调用就是在调用C和C++的代码，比如Thread类，底层实际调用的就是thread.c和thread.cpp的代码。当我们在如下的Java代码调用到start的时候，实际会调用到 <strong>private native void start0();</strong> 这一行代码，这一行代码在jdk中就会调用thread.c中的<a href="https://github.com/JetBrains/jdk8u_jdk/blob/master/src/share/native/java/lang/Thread.c#L44">JVM_StartThread</a>，实际上是依赖C去调用操作系统底层的代码。C中的JVM_StartThread会调用到hotspot虚拟机中的C++方法<a href="https://github.com/JetBrains/jdk8u_hotspot/blob/c39701c890a5960dfa7c325b78ee97085646f57d/src/share/vm/prims/jvm.cpp#L3076">JVM_StartThread</a>，使用代码<a href="https://github.com/JetBrains/jdk8u_hotspot/blob/c39701c890a5960dfa7c325b78ee97085646f57d/src/share/vm/prims/jvm.cpp#L3144">Thread::start(native_thread);</a>又可以调用到<a href="https://github.com/JetBrains/jdk8u_hotspot/blob/c39701c890a5960dfa7c325b78ee97085646f57d/src/share/vm/runtime/thread.cpp#L473">os::start_thread(thread);</a>代码，通过os底层创建一个线程。</p>
<h3 id="3-进程线程管程概念"><a href="#3-进程线程管程概念" class="headerlink" title="3. 进程线程管程概念"></a>3. 进程线程管程概念</h3><p>进程：程序的一次执行，是一个独立单位，没一个进程都有自己的内存空间和系统资源，比如说一个QQ进程、Java程序进程。因为是隔离的，所以进程与进程之间基本上很少存在竞争关系。</p>
<p>线程：在一个进程内可以执行多个任务，每个任务就是一个线程，比如说在QQ中，可以同时去聊天，同时修改个人资料等。因为多个线程可以共用一片内存空间，所以多线程的并发问题就出来了。</p>
<p>管程：Monitor，监视器，实际上是一种同步机制，保证同一时间只有一个线程可以访问被保护的数据和代码。JVM中的<strong>synchronized</strong>就是通过monitor的进入和退出来实现的，每个对象都有monitor这个对象，每个对象都可以通过它来进行加锁。</p>
<h3 id="4-多线程带来的问题"><a href="#4-多线程带来的问题" class="headerlink" title="4. 多线程带来的问题"></a>4. 多线程带来的问题</h3><ol>
<li><strong>线程安全问题</strong>：多个线程竞争一个资源，比如说同时对i进行++操作，最后得出来的结果会是错误的。</li>
<li><strong>上下文切换导致的性能问题</strong>：单个处理器同一时间只能处理一个线程执行，但是CPU是通过时间片算法来执行的。CPU会根据线程的状态来动态切换，在切换时保存当前线程的状态，然后去处理别的任务，处理完后再回头接着保存的状态进行处理。</li>
<li><strong>死锁、锁饥饿问题</strong>：死锁就是两个线程分别加锁了两个对象，而两个线程又分别需要等待对方加锁的对象解锁，此时就陷入了互斥的状态。饥饿就是因为非公平锁存在多个线程排队竞争，有些线程会一直获取不到锁。</li>
</ol>
<h3 id="5-用户线程和守护线程"><a href="#5-用户线程和守护线程" class="headerlink" title="5. 用户线程和守护线程"></a>5. 用户线程和守护线程</h3><p>Java线程分为用户线程和守护线程，线程daemon属性为true表示是守护线程，false表示是用户线程。</p>
<p>守护线程：一种特殊线程，在后台完成一些系统性的服务，比如GC垃圾回收线程。当程序中的用户线程，包括main主线程执行完毕后，不管守护线程是否结束，系统都会自动退出。</p>
<p>用户线程：系统工作线程，用户创建的，比如说推送系统中的批量推送线程。main主线程结束了，别的用户线程都还会一直执行。</p>
<h3 id="6-什么是JUC"><a href="#6-什么是JUC" class="headerlink" title="6. 什么是JUC"></a>6. 什么是JUC</h3><p>JUC是<strong>java.util.concurrent</strong>包的简称，JDK1.5版本开始有的。Doug Lea主编写的。</p>
<h2 id="CompletableFuture详解"><a href="#CompletableFuture详解" class="headerlink" title="CompletableFuture详解"></a>CompletableFuture详解</h2><h3 id="1-FutureTask分析"><a href="#1-FutureTask分析" class="headerlink" title="1. FutureTask分析"></a>1. FutureTask分析</h3><p>原始的FutureTask会阻塞，会消耗大量资源，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FutureTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 创建一个future任务,并通过线程a启动</span></span><br><span class="line">        FutureTask&lt;Integer&gt; futureTask = <span class="keyword">new</span> FutureTask&lt;&gt;(() -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;执行任务逻辑----start&quot;</span>);</span><br><span class="line">            Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;执行任务逻辑----end&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;);</span><br><span class="line">        <span class="keyword">new</span> Thread(futureTask, <span class="string">&quot;a&quot;</span>).start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. get()会阻塞运行，下面的main线程会被阻塞</span></span><br><span class="line">        System.out.println(futureTask.get());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 加入时间可以设置超时时间，如果超过1秒钟就不再阻塞。</span></span><br><span class="line">        System.out.println(futureTask.get(<span class="number">1000</span>, TimeUnit.MILLISECONDS));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 通过轮询的方式获取，也会阻塞住main运行，还会消耗无畏的CPU资源。</span></span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span>(futureTask.isDone())&#123;</span><br><span class="line">                System.out.println(futureTask.get());</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;继续等待&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(Thread.currentThread().getName() + <span class="string">&quot;线程正在运行&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="2-CompletableFuture：對FutureTask的改进版"><a href="#2-CompletableFuture：對FutureTask的改进版" class="headerlink" title="2. CompletableFuture：對FutureTask的改进版"></a>2. CompletableFuture：對FutureTask的改进版</h3><p>CompletableFuture可以直接给回调，不阻塞了。也能将多个异步任务组合成一个异步计算，可以等待所有异步任务都完成后返回结果等等。比如说电商系统中，查询商品详情要调用库存服务查询库存，调用营销服务查询活动，调用商品服务查询商详等等，就可以通过CompletableFuture创建多个线程任务来并发查询，查询完成后通过组合结果来返回，避免了单线程的效率低下问题。CompletableFuture实现了CompletionStage接口，就能实现这种阶段性的任务。</p>
<p>举个Linux的小例子：<strong>ps -ef | grep java</strong>,这个命令的grep java就依赖了ps -ef的结果。</p>
<p>CompletableFuture优点：<br>1.异步任务结束时，会自动回调某个对象的方法。<br>2.异步任务出错时，会自动回调某个对象的方法。<br>3.主线程设置好回调后，不再关心异步任务的执行，异步任务之间可以顺序执行。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FutureTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//1. 创建一个线程池，如果CompletableFuture没有指定，就默认用ForkJoinPool.commonPool()作为线程池。</span></span><br><span class="line">        ThreadPoolExecutor threadPoolExecutor = <span class="keyword">new</span> ThreadPoolExecutor(</span><br><span class="line">                <span class="number">1</span>, <span class="number">20</span>,</span><br><span class="line">                <span class="number">1L</span>, TimeUnit.SECONDS, <span class="keyword">new</span> LinkedBlockingDeque&lt;&gt;(<span class="number">50</span>),</span><br><span class="line">                Executors.defaultThreadFactory(),</span><br><span class="line">                <span class="keyword">new</span> ThreadPoolExecutor.AbortPolicy()</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 使用runAsync运行无返回任务</span></span><br><span class="line">        CompletableFuture.runAsync(() -&gt; System.out.println(<span class="string">&quot;使用runAsync运行无返回任务&quot;</span>), threadPoolExecutor);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 使用supplyAsync运行有返回任务</span></span><br><span class="line">        CompletableFuture future2 = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">&quot;使用supplyAsync运行有返回任务&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;使用supplyAsync运行有返回任务&quot;</span>;</span><br><span class="line">        &#125;, threadPoolExecutor);</span><br><span class="line">        <span class="comment">//通过then的方式异步获取结果并打印，不会阻塞main线程的运行</span></span><br><span class="line">        future2.thenAccept(System.out::println);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//此时main运行就不会和FutureTask一样被阻塞</span></span><br><span class="line">        System.out.println(Thread.currentThread().getName() + <span class="string">&quot;正在运行&quot;</span>);</span><br><span class="line"></span><br><span class="line">        threadPoolExecutor.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="3-CompletableFuture案例"><a href="#3-CompletableFuture案例" class="headerlink" title="3. CompletableFuture案例"></a>3. CompletableFuture案例</h3><p>电商商详页在获取详情时，需要获取SPU基本信息，SKU集合，SPU图片列表，属性等，如果线性获取的话极其费时，此时启动一批CompletableFuture任务来并发执行，再通过CompletableFuture.allOf就可以等待所有任务执行完成后获取结果。</p>
<p>其中，我们还能使用thenAcceptAsync方法，让一个任务的结果依赖其他的任务。案例中的SPU规格参数获取就要依赖第一步的SPU基本信息。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> CustomProductDetailVO <span class="title">detail</span><span class="params">(Long productId)</span> </span>&#123;</span><br><span class="line">    CustomProductDetailVO result = <span class="keyword">new</span> CustomProductDetailVO();</span><br><span class="line">    <span class="comment">//获取SPU的基本信息</span></span><br><span class="line">    CompletableFuture&lt;Product&gt; productInfoFuture = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">        Product product = <span class="keyword">this</span>.getOne(<span class="keyword">new</span> LambdaQueryWrapper&lt;Product&gt;().eq(Product::getId, productId));</span><br><span class="line">        ProductVO productVO = dozerUtils.map(product, ProductVO.class);</span><br><span class="line">        result.setProductVO(productVO);</span><br><span class="line">        <span class="keyword">return</span> product;</span><br><span class="line">    &#125;, executor);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取SPU下的SKU集合</span></span><br><span class="line">    CompletableFuture&lt;Void&gt; skuVoFuture = CompletableFuture.runAsync(() -&gt; &#123;</span><br><span class="line">        List&lt;Sku&gt; skuList = skuService.list(<span class="keyword">new</span> LambdaQueryWrapper&lt;Sku&gt;().eq(Sku::getProductId, productId));</span><br><span class="line">        List&lt;SkuVO&gt; skuVOS = BeanCopierUtils.copyListProperties(skuList, SkuVO::<span class="keyword">new</span>);</span><br><span class="line">        List&lt;Long&gt; skuIds = skuVOS.stream().map(SkuVO::getId).collect(Collectors.toList());</span><br><span class="line">        List&lt;InventorySkuDTO&gt; stockList = productStockService.getSaleStockQuantity(skuIds);</span><br><span class="line">        result.setSkus(skuVOS);</span><br><span class="line">        result.setSkuStocks(stockList);</span><br><span class="line">    &#125;, executor);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取SPU的图片列表</span></span><br><span class="line">    CompletableFuture&lt;Void&gt; imagesFuture = CompletableFuture.runAsync(() -&gt; &#123;</span><br><span class="line">        LambdaQueryWrapper&lt;ProductImages&gt; queryWrapper = <span class="keyword">new</span> LambdaQueryWrapper&lt;&gt;();</span><br><span class="line">        queryWrapper.eq(ProductImages::getProductId, productId);</span><br><span class="line">        queryWrapper.orderByDesc(ProductImages::getSort);</span><br><span class="line">        List&lt;ProductImages&gt; imageList = productImagesService.list(queryWrapper);</span><br><span class="line">        result.setImages(BeanCopierUtils.copyListProperties(imageList, ProductImagesVO::<span class="keyword">new</span>));</span><br><span class="line">    &#125;, executor);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取SPU的销售属性的多个组合</span></span><br><span class="line">    CompletableFuture&lt;Void&gt; saleAttrFuture = CompletableFuture.runAsync(() -&gt; &#123;</span><br><span class="line"></span><br><span class="line">        List&lt;SkuDetailSaleAttributeVO&gt; saleAttrs = skuSaleAttributeValueService.listSaleAttrs(productId);</span><br><span class="line">        result.setSaleAttr(saleAttrs);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置分组参数</span></span><br><span class="line">        Map&lt;String, List&lt;SkuDetailSaleAttributeVO&gt;&gt; saleAttrsGroupMap = saleAttrs.stream().collect(Collectors.groupingBy(SkuDetailSaleAttributeVO::getAttributeName, Collectors.toList()));</span><br><span class="line">        List&lt;SaleAttrGroupVO&gt; groupVOS = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (List&lt;SkuDetailSaleAttributeVO&gt; value : saleAttrsGroupMap.values()) &#123;</span><br><span class="line">            groupVOS.add(<span class="keyword">new</span> SaleAttrGroupVO(value.get(<span class="number">0</span>).getAttributeId(), value.get(<span class="number">0</span>).getAttributeName(), value));</span><br><span class="line">        &#125;</span><br><span class="line">        result.setSaleAttrGroup(groupVOS);</span><br><span class="line">    &#125;, executor);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//获取SPU的规格参数，依赖第一步获取的Product信息，需要里面的categoryId参数</span></span><br><span class="line">    CompletableFuture&lt;Void&gt; attrGroupFuture = productInfoFuture.thenAcceptAsync(productInfo -&gt; &#123;</span><br><span class="line"></span><br><span class="line">        List&lt;SpuDetailAttrGroupVo&gt; baseAttrs = productAttributeValueService.getProductGroupAttrsBySpuId(productInfo.getId(), productInfo.getCategoryId());</span><br><span class="line">        result.setGroupAttrs(baseAttrs);</span><br><span class="line">    &#125;, executor);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        CompletableFuture.allOf(productInfoFuture, skuVoFuture, imagesFuture, saleAttrFuture, attrGroupFuture).get();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        log.error(<span class="string">&quot;获取商品详情线程池运行失败, 商品ID: &quot;</span> + productId, e);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="Java锁"><a href="#Java锁" class="headerlink" title="Java锁"></a>Java锁</h2><h3 id="简单理解悲观锁和乐观锁"><a href="#简单理解悲观锁和乐观锁" class="headerlink" title="简单理解悲观锁和乐观锁"></a>简单理解悲观锁和乐观锁</h3><p><strong>悲观锁</strong>认为自己在使用数据的时候一定有别的线程也来使用数据，所以悲观锁在获取数据的时候就会先加锁，确保数据不会被其他线程修改到。synchronized和Lock的实现类都是悲观锁。</p>
<p><strong>乐观锁</strong>认为自己在使用数据的时候不会有其他线程来修改数据，不会加锁，只会去判断在修改数据的一刻有没有其他线程更新了数据，如果没被其他线程更新，则直接修改数据，如果被更新了，就根据当前锁的实现方式做不同的处理。 一般都是采用无锁方式实现，比如CAS算法，Atomic原子类就是通过CAS实现，一种自旋锁，通过while循环不断去判断是否被其他线程更新了的方式。</p>
<p>git是一个乐观锁很好的例子，当写好了代码进行提交时，因为有其他人在这之前提交了一次，此次代码提交是无法提交上去的，必须先拉下代码来，才能再提交上去。</p>
<h3 id="synchorized-8锁"><a href="#synchorized-8锁" class="headerlink" title="synchorized 8锁"></a>synchorized 8锁</h3><ol>
<li><p><strong>两个加了synchronized修饰的普通方法，同一个对象调用</strong>，分别在两个线程中调用对象方法的时候，这个synchronized会锁住整个对象，执行时会按照调用顺序进行输出。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Phone</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1. 先调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">sendSms</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;send sms&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//2. 后调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">playGame</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;play game&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>两个加了synchronized修饰的普通方法，先调用的加了3秒休眠，同一个对象调用</strong>，这个时候会阻塞住三秒，等待sendSms执行完成后再执行playGame。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Phone</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1. 先调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">sendSms</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">3</span>);</span><br><span class="line">        log.info(<span class="string">&quot;send sms&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//2. 后调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">playGame</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;play game&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>一个加了synchronized的普通方法，一个没加锁的普通方法，同一个对象调用</strong>，这个时候，looklookShell直接输出，sendSms等待3秒后输出。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Phone</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1. 先调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">sendSms</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">3</span>);</span><br><span class="line">        log.info(<span class="string">&quot;send sms&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//2. 后调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">looklookShell</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;looklookShell&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>两个加锁普通方法，两个不同的对象分别调用</strong>，此时后调用的会先输出，因为不是同一个对象，用的锁也不是同一把。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Phone</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1. A对象先调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">sendSms</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">3</span>);</span><br><span class="line">        log.info(<span class="string">&quot;send sms&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//2. B对象后调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">playGame</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;play game&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>两个加锁的静态方法，同一个对象调用</strong>，这个时候因为是静态方法加锁，此时锁的是这个类本身。所以此时同一个对象调用的话会按照调用顺序输出。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Phone</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1. 先调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">sendSms</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">3</span>);</span><br><span class="line">        log.info(<span class="string">&quot;send sms&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//2. 后调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">playGame</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;play game&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>两个加锁的静态方法，两个对象分别调用</strong>，这也是将整个类锁住了，此时两个对象分别调用静态同步方法的话也会按照先后顺序输出。</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Phone</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1. A对象先调用，等待3秒，先输出</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">sendSms</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">3</span>);</span><br><span class="line">        log.info(<span class="string">&quot;send sms&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//2. B对象后调用，在A执行完后立马执行</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">playGame</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;play game&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="7">
<li><p><strong>一个静态同步方法，一个普通同步方法，同一个对象进行调用</strong>，普通同步方法会先输出，静态同步方法会后输出。静态的和非静态的锁是两个不同的对象，两者无竞态条件，所以无休眠的普通方法会先输出。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Phone</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1. 先调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">sendSms</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">3</span>);</span><br><span class="line">        log.info(<span class="string">&quot;send sms&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//2. 后调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">playGame</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;play game&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>一个静态同步方法，一个普通同步方法，两个对象分别进行调用</strong>，普通同步方法会先输出，静态同步方法会后输出。静态的和非静态的锁是两个不同的对象，两者无竞态条件，所以无休眠的普通方法会先输出。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Phone</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1. 先调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">sendSms</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        TimeUnit.SECONDS.sleep(<span class="number">3</span>);</span><br><span class="line">        log.info(<span class="string">&quot;send sms&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//2. 后调用</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">playGame</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;play game&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<p>8锁总结：</p>
<ol>
<li><p>一个对象里面如果有多个synchronized方法，某一个时刻内，只要一个线程去调用其中的一个synchronized方法了，其它的线程都只能等待，换句话说，某一个时刻内，只能有唯一一个线程去访问这些synchronized方法</p>
</li>
<li><p>锁的是当前对象this，被锁定后，其它的线程都不能进入到当前对象的其它的synchronized方法</p>
</li>
<li><p>加个普通方法后发现和同步锁无关</p>
</li>
<li><p>换成两个对象后，不是同一把锁了，情况立刻变化。</p>
</li>
<li><p>都换成静态同步方法后，情况又变化</p>
</li>
</ol>
<p>所有的非静态同步方法用的都是同一把锁——实例对象本身，也就是说如果一个实例对象的非静态同步方法获取锁后，该实例对象的其他非静态同步方法必须等待获取锁的方法释放锁后才能获取锁，可是别的实例对象的非静态同步方法因为跟该实例对象的非静态同步方法用的是不同的锁，所以毋须等待该实例对象已获取锁的非静态同步方法释放锁就可以获取他们自己的锁。</p>
<p>所有的静态同步方法用的也是同一把锁——类对象本身，这两把锁是两个不同的对象，所以静态同步方法与非静态同步方法之间是不会有竞态条件的。但是一旦一个静态同步方法获取锁后，其他的静态同步方法都必须等待该方法释放锁后才能获取锁，而不管是同一个实例对象的静态同步方法之间，还是不同的实例对象的静态同步方法之间，只要它们同一个类的实例对象！</p>
<h3 id="Synchronized字节码分析"><a href="#Synchronized字节码分析" class="headerlink" title="Synchronized字节码分析"></a>Synchronized字节码分析</h3><p>对如下Java代码编译，会得到class字节码文件。再使用<strong>javap -c xxx.class</strong>命令，就可以得到反编译后的字节码文件。</p>
<p>synchronized底层就是通过monitorexit和monitorenter实现的，如下会出现两次monitorexit，是因为其要保证锁能够在出现异常的情况下也能正常解锁。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//java代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SyncDemo</span> </span>&#123;</span><br><span class="line">    Object lock = <span class="keyword">new</span> Object();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通过javap -v SyncDemo.class 反编译字节码文件</span></span><br><span class="line"><span class="comment">     * 能够看到是一个monitorenter对应了两个monitorexit,是因为多出来的exit需要保证在发生了异常后也能够正常解锁</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;lock in&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 一个monitorenter对应一个monitorexit，因为在同步代码块中抛出了异常，此时仅需要一次抛出异常的退出。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;lock in&quot;</span>);</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;e&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 此处会在方法上的flag标记为ACC_SYNCHRONIZED，方法级别的同步时隐式的，</span></span><br><span class="line"><span class="comment">     * 无需要字节码的monitorenter和monitorexit来控制，它实现在方法的调用</span></span><br><span class="line"><span class="comment">     * 和返回操作之中，虚拟机可以通过ACC_SYNCHRONIZED标志来判断。执行线程</span></span><br><span class="line"><span class="comment">     * 看到方法设置了此标识就会先持有管程，然后才能执行方法，最后方法完成就释放</span></span><br><span class="line"><span class="comment">     * 管程，在持有期间，别的线程无法再去获取到。</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * 如果一个同步方法执行期间抛出了异常，并且方法内部无法处理的时候，那么这个管程</span></span><br><span class="line"><span class="comment">     * 将在异常抛出到同步方法边界之外时自动释放。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">test3</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;test2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 此处会在方法的flag标记为ACC_STATIC, ACC_SYNCHRONIZED</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">test4</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;test2&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>javap -c xxx.class后得到结果：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">com</span>.<span class="title">whoiszxl</span>.<span class="title">juc</span>.<span class="title">SyncDemo</span> </span>&#123;</span><br><span class="line">  java.lang.Object lock;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> com.whoiszxl.juc.SyncDemo();</span><br><span class="line">    Code:</span><br><span class="line">       <span class="number">0</span>: aload_0</span><br><span class="line">       <span class="number">1</span>: invokespecial #<span class="number">1</span>                  <span class="comment">// Method java/lang/Object.&quot;&lt;init&gt;&quot;()V</span></span><br><span class="line">       <span class="number">4</span>: aload_0</span><br><span class="line">       <span class="number">5</span>: <span class="keyword">new</span>           #<span class="number">2</span>                  <span class="comment">// class java/lang/Object</span></span><br><span class="line">       <span class="number">8</span>: dup</span><br><span class="line">       <span class="number">9</span>: invokespecial #<span class="number">1</span>                  <span class="comment">// Method java/lang/Object.&quot;&lt;init&gt;&quot;()V</span></span><br><span class="line">      <span class="number">12</span>: putfield      #<span class="number">3</span>                  <span class="comment">// Field lock:Ljava/lang/Object;</span></span><br><span class="line">      <span class="number">15</span>: <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span></span>;</span><br><span class="line">    Code:</span><br><span class="line">       <span class="number">0</span>: aload_0</span><br><span class="line">       <span class="number">1</span>: getfield      #<span class="number">3</span>                  <span class="comment">// Field lock:Ljava/lang/Object;</span></span><br><span class="line">       <span class="number">4</span>: dup</span><br><span class="line">       <span class="number">5</span>: astore_1</span><br><span class="line">       <span class="number">6</span>: monitorenter</span><br><span class="line">       <span class="number">7</span>: getstatic     #<span class="number">4</span>                  <span class="comment">// Field java/lang/System.out:Ljavaio/PrintStream;</span></span><br><span class="line">      <span class="number">10</span>: ldc           #<span class="number">5</span>                  <span class="comment">// String lock in</span></span><br><span class="line">      <span class="number">12</span>: invokevirtual #<span class="number">6</span>                  <span class="comment">// Method java/io/PrintStream.printn:(Ljava/lang/String;)V</span></span><br><span class="line">      <span class="number">15</span>: aload_1</span><br><span class="line">      <span class="number">16</span>: monitorexit</span><br><span class="line">      <span class="number">17</span>: goto          <span class="number">25</span></span><br><span class="line">      <span class="number">20</span>: astore_2</span><br><span class="line">      <span class="number">21</span>: aload_1</span><br><span class="line">      <span class="number">22</span>: monitorexit  <span class="comment">//////此处test1会有两个exit操作</span></span><br><span class="line">      <span class="number">23</span>: aload_2</span><br><span class="line">      <span class="number">24</span>: athrow</span><br><span class="line">      <span class="number">25</span>: <span class="keyword">return</span></span><br><span class="line">    Exception table:</span><br><span class="line">       from    to  target type</span><br><span class="line">           <span class="number">7</span>    <span class="number">17</span>    <span class="number">20</span>   any</span><br><span class="line">          <span class="number">20</span>    <span class="number">23</span>    <span class="number">20</span>   <span class="function">any</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test2</span><span class="params">()</span></span>;</span><br><span class="line">    Code:</span><br><span class="line">       <span class="number">0</span>: aload_0</span><br><span class="line">       <span class="number">1</span>: getfield      #<span class="number">3</span>                  <span class="comment">// Field lock:Ljava/lang/Object;</span></span><br><span class="line">       <span class="number">4</span>: dup</span><br><span class="line">       <span class="number">5</span>: astore_1</span><br><span class="line">       <span class="number">6</span>: monitorenter</span><br><span class="line">       <span class="number">7</span>: getstatic     #<span class="number">4</span>                  <span class="comment">// Field java/lang/System.out:Ljavaio/PrintStream;</span></span><br><span class="line">      <span class="number">10</span>: ldc           #<span class="number">5</span>                  <span class="comment">// String lock in</span></span><br><span class="line">      <span class="number">12</span>: invokevirtual #<span class="number">6</span>                  <span class="comment">// Method java/io/PrintStream.printn:(Ljava/lang/String;)V</span></span><br><span class="line">      <span class="number">15</span>: <span class="keyword">new</span>           #<span class="number">7</span>                  <span class="comment">// class java/lang/RuntimeException</span></span><br><span class="line">      <span class="number">18</span>: dup</span><br><span class="line">      <span class="number">19</span>: ldc           #<span class="number">8</span>                  <span class="comment">// String e</span></span><br><span class="line">      <span class="number">21</span>: invokespecial #<span class="number">9</span>                  <span class="comment">// Method java/lang/RuntimeExceptio.&quot;&lt;init&gt;&quot;:(Ljava/lang/String;)V</span></span><br><span class="line">      <span class="number">24</span>: athrow</span><br><span class="line">      <span class="number">25</span>: astore_2</span><br><span class="line">      <span class="number">26</span>: aload_1</span><br><span class="line">      <span class="number">27</span>: monitorexit    <span class="comment">//////test2仅一次exit</span></span><br><span class="line">      <span class="number">28</span>: aload_2</span><br><span class="line">      <span class="number">29</span>: athrow</span><br><span class="line">    Exception table:</span><br><span class="line">       from    to  target type</span><br><span class="line">           <span class="number">7</span>    <span class="number">28</span>    <span class="number">25</span>   <span class="function">any</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">  <span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">test3</span><span class="params">()</span></span>;  <span class="comment">///通过javap -v 才能打印出详细信息</span></span><br><span class="line">    descriptor: ()V</span><br><span class="line">    flags: ACC_PUBLIC, ACC_SYNCHRONIZED <span class="comment">///此处标记为ACC_SYNCHRONIZED</span></span><br><span class="line">    Code:</span><br><span class="line">      stack=<span class="number">2</span>, locals=<span class="number">1</span>, args_size=<span class="number">1</span></span><br><span class="line">         <span class="number">0</span>: getstatic     #<span class="number">4</span>                  <span class="comment">// Field java/lang/System.out:Ljava/io/PrintStream;</span></span><br><span class="line">         <span class="number">3</span>: ldc           #<span class="number">10</span>                 <span class="comment">// String test2</span></span><br><span class="line">         <span class="number">5</span>: invokevirtual #<span class="number">6</span>                  <span class="comment">// Method java/io/PrintStream.println:(Ljava/lang/String;)V</span></span><br><span class="line">         <span class="number">8</span>: <span class="keyword">return</span></span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line <span class="number">43</span>: <span class="number">0</span></span><br><span class="line">        line <span class="number">44</span>: <span class="number">8</span></span><br><span class="line">      LocalVariableTable:</span><br><span class="line">        Start  Length  Slot  Name   Signature</span><br><span class="line">            <span class="number">0</span>       <span class="number">9</span>     <span class="number">0</span>  <span class="keyword">this</span>   Lcom/whoiszxl/juc/SyncDemo;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">test4</span><span class="params">()</span></span>;</span><br><span class="line">    descriptor: ()V</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC, ACC_SYNCHRONIZED</span><br><span class="line">    Code:</span><br><span class="line">      stack=<span class="number">2</span>, locals=<span class="number">0</span>, args_size=<span class="number">0</span></span><br><span class="line">         <span class="number">0</span>: getstatic     #<span class="number">4</span>                  <span class="comment">// Field java/lang/System.out:Ljava/io/PrintStream;</span></span><br><span class="line">         <span class="number">3</span>: ldc           #<span class="number">10</span>                 <span class="comment">// String test2</span></span><br><span class="line">         <span class="number">5</span>: invokevirtual #<span class="number">6</span>                  <span class="comment">// Method java/io/PrintStream.println:(Ljava/lang/String;)V</span></span><br><span class="line">         <span class="number">8</span>: <span class="keyword">return</span></span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line <span class="number">50</span>: <span class="number">0</span></span><br><span class="line">        line <span class="number">51</span>: <span class="number">8</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>cpp底层源码分析：<br>每个对象都自带一个monitor，在hotspot虚拟机中，monitor是采用ObjectMonitor实现的，我们可以在<a href="https://github.com/JetBrains/jdk8u_hotspot/blob/8u152/agent/src/share/classes/sun/jvm/hotspot/runtime/ObjectMonitor.java">ObjectMonitor.java</a>里看到具体的代码实现，其次的实现是在<a href="https://github.com/JetBrains/jdk8u_hotspot/blob/8u152/src/share/vm/runtime/objectMonitor.cpp">ObjectMonitor.cpp</a>里，我们可以在其中找到一些Java中<strong>notify,notifyAll,wait,tryLock</strong>等实现。</p>
<p>我们还能够在它的头定义<a href="https://github.com/JetBrains/jdk8u_hotspot/blob/8u152/src/share/vm/runtime/objectMonitor.hpp#L140">ObjectMonitor.hpp</a>里找到一系列关键属性，比如如下几个：</p>
<ol>
<li>_owner: 指向了持有Monitor锁的线程。</li>
<li>_WaitSet：存放了处于wait状态的线程队列。</li>
<li>_EntryList：存放了处于等待锁block状态的线程队列。</li>
<li>_recursions：锁的重入次数。</li>
<li>_count：记录该线程获取锁的次数。</li>
</ol>
<h3 id="公平锁和非公平锁"><a href="#公平锁和非公平锁" class="headerlink" title="公平锁和非公平锁"></a>公平锁和非公平锁</h3><p>先来后到，先进先出就是公平，能插队的就是非公平。</p>
<p>ReentrantLock简要实现原理</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span> state;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">tryAcquire</span><span class="params">(<span class="keyword">int</span> acquires)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1. 获取到当前线程</span></span><br><span class="line">    <span class="keyword">final</span> Thread current = Thread.currentThread();</span><br><span class="line">    <span class="comment">//2. 获取到当前锁的state值</span></span><br><span class="line">    <span class="keyword">int</span> c = getState();</span><br><span class="line">    <span class="comment">//3. 如果state值为0，则是无线程占用锁</span></span><br><span class="line">    <span class="keyword">if</span> (c == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">//4. 公平锁比非公平锁就多了!hasQueuedPredecessors判断，判断队列前是否有排队，</span></span><br><span class="line">        <span class="comment">//公平锁可以保证公平，大家都有份，非公平锁则破坏了这个规定，导致部分线程长时间</span></span><br><span class="line">        <span class="comment">//在排队，无法获取到锁，导致锁饥饿。</span></span><br><span class="line">        <span class="comment">//公平锁因为多一层判断，所以会有一定时间差。所以效率会低一些。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//5. compareAndSetState则通过CAS对state进行设置为1</span></span><br><span class="line">        <span class="keyword">if</span> (!hasQueuedPredecessors() &amp;&amp; </span><br><span class="line">            compareAndSetState(<span class="number">0</span>, acquires)) &#123;</span><br><span class="line">            <span class="comment">//6. 设置占用线程为当前线程并返回true</span></span><br><span class="line">            setExclusiveOwnerThread(current);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//7. 如果state不为0，并且当前线程等于锁占用的线程，则说明锁重入了。</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (current == getExclusiveOwnerThread()) &#123;</span><br><span class="line">        <span class="comment">//8. 直接将state设置为+1</span></span><br><span class="line">        <span class="keyword">int</span> nextc = c + acquires;</span><br><span class="line">        <span class="keyword">if</span> (nextc &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> Error(<span class="string">&quot;Maximum lock count exceeded&quot;</span>);</span><br><span class="line">        setState(nextc);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//9. 如果是false，则说明是其他线程，直接返回false。</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="可重入锁"><a href="#可重入锁" class="headerlink" title="可重入锁"></a>可重入锁</h3><p>可重入锁又名递归锁，在外层使用锁后，在内层依旧可以使用，并且不死锁。比如说在synchronized方法或者其修饰的代码块里调用本类的其他synchronized修饰的方法或代码块时，是永远可以得到锁的。</p>
<p>每个锁对象都有一个锁计数器和一个指向持有该锁的线程指针，monitorenter执行时，如果计数器为0，则给0加1，并设置指针为指向当前线程；当计数器为1并且指针是指向当前线程，则计数器1再加1；如果计数器不为0且指针没指向该线程，则被锁住。</p>
<p>隐式锁，synchronized关键字使用的锁：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LockDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">helloOne</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;hello one&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">helloTwo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        helloOne();</span><br><span class="line">        System.out.println(<span class="string">&quot;hello two&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        helloTwo();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>显示锁，Lock类：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LockDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> ReentrantLock lock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        System.out.println(<span class="string">&quot;lock1&quot;</span>);</span><br><span class="line">        lock.lock();</span><br><span class="line">        System.out.println(<span class="string">&quot;lock2&quot;</span>);</span><br><span class="line">        lock.unlock();</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h3><p>死锁就是两个或两个以上的线程在执行过程中互相争夺对方的锁，比如说线程A和B，A持有a锁，B持有b锁，A要获取b锁，B要获取a锁，互不想让导致陷入死锁。还有系统不足、进程运行推进的顺序不合适、资源分配不当的原因也会导致死锁。</p>
<p>如何排查死锁：</p>
<ol>
<li>jps 命令获取到进程id，通过jstack pid打印出结果。</li>
<li>使用jconsole图形化界面进行远程或本地连接到进程，查询死锁。</li>
</ol>
<p>死锁Demo</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DeadLockDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> ReentrantLock lock1 = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">    <span class="keyword">static</span> ReentrantLock lock2 = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Object o1 = <span class="keyword">new</span> Object();</span><br><span class="line">        Object o2 = <span class="keyword">new</span> Object();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (o1) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(<span class="string">&quot;o1执行&quot;</span>);</span><br><span class="line">                <span class="keyword">synchronized</span> (o2) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;o2执行&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (o2) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;o2执行&quot;</span>);</span><br><span class="line">                <span class="keyword">synchronized</span> (o1) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;o1执行&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">dead1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                lock1.lock();</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line"></span><br><span class="line">                lock2.lock();</span><br><span class="line">                System.out.println(<span class="string">&quot;lock2逻辑运行&quot;</span>);</span><br><span class="line">                lock2.unlock();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">                lock1.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="string">&quot;t1&quot;</span>).start();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                lock2.lock();</span><br><span class="line">                Thread.sleep(<span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line">                lock1.lock();</span><br><span class="line">                System.out.println(<span class="string">&quot;lock2逻辑运行&quot;</span>);</span><br><span class="line">                lock1.unlock();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">                lock2.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="string">&quot;t2&quot;</span>).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="LockSupport线程中断机制"><a href="#LockSupport线程中断机制" class="headerlink" title="LockSupport线程中断机制"></a>LockSupport线程中断机制</h2><h3 id="线程中断机制"><a href="#线程中断机制" class="headerlink" title="线程中断机制"></a>线程中断机制</h3><p><strong>线程中断的概念</strong>：<br>一个线程中断不应由其他线程来决定中断或停止，而应由当前线程自己决定。Thread.stop()等方法已经被废弃。中断应该是一种协作机制，通过一个开关标识，其他线程通过控制开关标识，当前线程通过读取开关标识来对应进行中断恢复。</p>
<p><strong>三种实现方式，volatile，AtomicBoolean和Thread自带的API方式</strong><br>三种方式的本质都是用一个中间标记，其他线程仅仅是修改这个中间标记为中断状态，是否中断还是看当前线程的内部处理，通过监听这个中间标记来做出对应的操作。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InterruptThreadDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//中断开关标记，通过volatile修饰保证多线程中此值的可见性</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> stopFlag = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//和boolean原理一样</span></span><br><span class="line">    <span class="keyword">static</span> AtomicBoolean atomicFlag = <span class="keyword">new</span> AtomicBoolean(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">//创建一个线程，执行while死循环，通过标记控制。</span></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">while</span> (!stopFlag) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;执行任务逻辑&quot;</span>);</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">100</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">&quot;退出了程序&quot;</span>);</span><br><span class="line">        &#125;).start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//休眠5秒后修改标记值为关闭状态</span></span><br><span class="line">        Thread.sleep(<span class="number">5000</span>);</span><br><span class="line">        stopFlag = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="实现方式二：Thread自带中断API实现"><a href="#实现方式二：Thread自带中断API实现" class="headerlink" title="实现方式二：Thread自带中断API实现"></a>实现方式二：Thread自带中断API实现</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">InterruptThreadDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Thread t1 = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;执行任务。。。。。&quot;</span>);</span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span>(Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;线程被标记为中断，程序结束&quot;</span>);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="string">&quot;t1&quot;</span>);</span><br><span class="line">        t1.start();</span><br><span class="line">        </span><br><span class="line">        System.out.println(<span class="string">&quot;线程是否中断状态：&quot;</span> + t1.isInterrupted());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//休眠1秒后发送中断信号</span></span><br><span class="line">        <span class="comment">//这个中断调用实际上不能结束线程，只是修改了一个状态值。</span></span><br><span class="line">        <span class="comment">//需要被中断的线程一起配合才能达到中断的效果。</span></span><br><span class="line">        <span class="comment">//如果线程处于被阻塞状态（sleep,wait,join）等状态，调用的时候会抛出异常。</span></span><br><span class="line">        <span class="comment">//如果要解决这个异常，就需要在sleep等阻塞代码的catch块中再中断一下：</span></span><br><span class="line">        <span class="comment">//加入这一行：Thread.currentThread().interrupt();</span></span><br><span class="line">        <span class="comment">//sleep方法抛出了InterruptedException后中断标识会被清空置为false，</span></span><br><span class="line">        <span class="comment">//如果catch没有调用.interrupt()再次将标识置为true就死循环了。</span></span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        t1.interrupt();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取到true，线程已经中断</span></span><br><span class="line">        System.out.println(<span class="string">&quot;线程是否中断状态：&quot;</span> + t1.isInterrupted());</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Thread 中断API还有一个静态方法：Thread.interrupted(); 这个方法是先返回当前线程的中断状态，然后再将中断状态置为false。</p>
</blockquote>
<h3 id="LockSupport"><a href="#LockSupport" class="headerlink" title="LockSupport"></a>LockSupport</h3><p>LockSupport是用来创建锁和其他同步类的基本线程阻塞原语。其中的park()和unpark()分别用来阻塞线程和接触阻塞。</p>
<h4 id="三种方式让线程等待唤醒的方法"><a href="#三种方式让线程等待唤醒的方法" class="headerlink" title="三种方式让线程等待唤醒的方法"></a>三种方式让线程等待唤醒的方法</h4><ol>
<li><p>第一种：使用Object中的wait()和notify()让线程等待和唤醒，<strong>wait()和notify()必须要在同步代码块或方法里成对顺序使用</strong>。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LockSupportDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Object lock = <span class="keyword">new</span> Object();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">//1. lock进入等待状态，需要在其他线程中调用notify才能再往下执行。</span></span><br><span class="line">                    lock.wait();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(<span class="string">&quot;等待结束，开始运行&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">                <span class="comment">//2. 唤醒操作，调用后 wait()的地方会被唤醒，往下执行逻辑。</span></span><br><span class="line">                lock.notify();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>第二种：使用JUC包中Lock的Condition中的await()和signal()让线程等待和唤醒，Condition中的线程等待和唤醒方法之前一定要先获取锁，并且要保证等待和唤醒的先后顺序，用法和Object的wait和notify类似。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LockSupportDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Lock lock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">        Condition condition = lock.newCondition();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            lock.lock();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;开启t1线程&quot;</span>);</span><br><span class="line">                condition.await();</span><br><span class="line">                System.out.println(<span class="string">&quot;执行t1线程等待后的逻辑&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">                lock.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="string">&quot;t1&quot;</span>).start();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            lock.lock();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">                condition.signal();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">                lock.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="string">&quot;t2&quot;</span>).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>第三种：通过LockSupport中的**park()和unpark(thread)**进行实现，其通过Permit(许可)的机制来做到阻塞和唤醒，每个线程只有一个Permit，permit只有0和1两个值，默认是0，类似Semaphore，但是permit的累加上限只是1。</p>
</li>
</ol>
<p>这种方式可以无锁实现，不需要synchronized和lock的加持也能使用，先唤醒后等待也支持。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LockSupportDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Thread t1 = <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;开启t1线程&quot;</span>);</span><br><span class="line">                <span class="comment">//1. 调用park阻塞住，等待许可发过来，才能继续往下执行</span></span><br><span class="line">                LockSupport.park();</span><br><span class="line">                LockSupport.park();</span><br><span class="line">                System.out.println(<span class="string">&quot;执行t1线程等待后的逻辑&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="string">&quot;t1&quot;</span>);</span><br><span class="line">        t1.start();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">                <span class="comment">//2. 此处发放许可，但是LockSupport许可最大只能为1，所以再多的unpark都只能发一张许可</span></span><br><span class="line">                <span class="comment">// 也就是说再多的unpark也只能解一个park()阻塞。</span></span><br><span class="line">                LockSupport.unpark(t1);</span><br><span class="line">                LockSupport.unpark(t1);</span><br><span class="line">                LockSupport.unpark(t1);</span><br><span class="line">                LockSupport.unpark(t1);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;, <span class="string">&quot;t2&quot;</span>).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Java内存模型-JMM"><a href="#Java内存模型-JMM" class="headerlink" title="Java内存模型 JMM"></a>Java内存模型 JMM</h2><p>在计算机的存储结构里，从本地磁盘-&gt;主内存-&gt;CPU三级缓存-&gt;CPU二级缓存-&gt;CPU一级缓存-&gt;寄存器，运行速度是逐步递增的，CPU的计算速度大大高于主内存，所以CPU在操作数据的时候是先将数据加载到缓存内进行操作的，此时内存里的数据和缓存中的数据就会存在不一致的情况。</p>
<p>此时JVM中就定义了一种Java内存模型（Java Memory Model），就是JMM，用来屏蔽掉各硬件和操作系统的内存访问差异，以实现Java程序在各种平台下都能达到一致的内存访问效果。</p>
<p>JMM本身是一种抽象概念，是一组约定或规范，不是真实存在的。主要关注点是多线程的<strong>原子性，可见性，有序性</strong>。</p>
<h3 id="原子性，可见性，有序性"><a href="#原子性，可见性，有序性" class="headerlink" title="原子性，可见性，有序性"></a>原子性，可见性，有序性</h3><p>可见性就是说：当一个线程修改了某个共享变量的值，其他线程是可以立即知道数据变更的。共享变量都是保存在主内存中的，CPU不能直接去去写主内存的数据，只能将主内存中的数据拷贝一份到自己的工作内存中，线程对数据的读写都要在工作内存中进行。可见性就要保证工作内存的数据能和主内存的数据能一致。</p>
<p>原子性就是指一个操作是不可被中断的，多线程环境下，操作不能被其他线程干扰。</p>
<p>有序性就是说：在编译器和处理器的优化下，一般会对指令进行重排序，有可能会产生脏读，两行代码执行时可能会优化为顺序颠倒，导致会因为数据依赖不对后有执行错误。</p>
<h3 id="多线程下变量的读写过程"><a href="#多线程下变量的读写过程" class="headerlink" title="多线程下变量的读写过程"></a>多线程下变量的读写过程</h3><ol>
<li>我们定义的所有共享变量都要存储在物理主内存中</li>
<li>每个线程都有自己独立的工作内存，里面保存着使用到的共享变量的副本。</li>
<li>线程对共享变量的操作不能直接去主内存里，只能在工作内存里先修改后再写回。</li>
<li>一个线程的工作内存无法访问另一个线程的工作内存，必须通过主内存来通信。</li>
</ol>
<h3 id="happens-before-先行发生"><a href="#happens-before-先行发生" class="headerlink" title="happens-before 先行发生"></a>happens-before 先行发生</h3><p>在JMM中，如果一个操作<strong>执行的结果</strong>需要对另一个操作可见性，或者代码重排序，那么这两个操作之间必须存在happens-before关系。</p>
<p>比如说：A线程执行了x=5, B线程执行了y=x, 如果线程A的操作先行发生于线程B的操作，那么可以确定y=5一定成立。如不存在此规则，则y!=5。happens-before是判断数据是否存在竞争，是否安全的非常有用的手段，依赖这个原则我们可以通过几条简单规则一揽子解决<strong>并发环境下两个操作之间是否可能存在冲突的所有问题</strong>，而不需要陷入进晦涩的底层编译原理中。</p>
<p><strong>happens-before总原则</strong><br>如果一个操作先行发生于另一个操作，那么第一个操作的执行结果将对第二个操作可见，且第一个操作的执行顺序在第二个之前。</p>
<p>两个操作之间存在先行发生关系，并不意味着一定要按照先行发生的原则制定的顺序来执行。如果重排序之后的执行结果按照先行发生的原则来执行的结果一直，那么这种重排序并不非法。比如说：1+2+3 重排为了 3+2+1</p>
<h3 id="happens-before-8条"><a href="#happens-before-8条" class="headerlink" title="happens-before 8条"></a>happens-before 8条</h3><ol>
<li><p>次序规则：一个线程内按代码顺序，前面的操作先行发生于写在后面的操作；前一个操作的结果可以被后续的操作获取。 讲白点就是前面一个操作把变量X赋值为1，那后面一个操作肯定能知道X已经变成了1。</p>
</li>
<li><p>锁定规则：一个unLock操作先行发生于后面((这里的“后面”是指时间上的先后))对同一个锁的lock操作；</p>
</li>
<li><p>volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作， 前面的写对后面的读是可见的,这里的“后面”同样是指时间上的先后。</p>
</li>
<li><p>传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；</p>
</li>
<li><p>线程启动规则(Thread Start Rule)：Thread对象的start()方法先行发生于此线程的每一个动作</p>
</li>
<li><p>线程中断规则(Thread Interruption Rule)：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；可以通过Thread.interrupted()检测到是否发生中断</p>
</li>
<li><p>线程终止规则(Thread Termination Rule)：线程中的所有操作都先行发生于对此线程的终止检 测，我们可以通过Thread::join()方法是否结束、 Thread::isAlive()的返回值等手段检测线程是否已经终止执行。</p>
</li>
<li><p>对象终结规则(Finalizer Rule)：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize()方法的开始。就是对象没有完成初始化之前，是不能调用finalized()方法的</p>
</li>
</ol>
<h2 id="volatile与JMM"><a href="#volatile与JMM" class="headerlink" title="volatile与JMM"></a>volatile与JMM</h2><p>volatile是一个修饰变量的关键字，修饰后可保证该变量具有可见性与有序性。</p>
<p>当写一个volatile变量时，JMM会把该线程对应的工作内存中的共享变量值立即刷新回主内存中。<br>当读一个volatile变量时，JMM会把该线程对应的工作内存设置为无效，直接从主内存中读取共享变量。<br>volatile的写内存语义是直接刷到主内存中，读的内存语义是直接从主内存中读取。</p>
<h3 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h3><p>保证可见性的手段是防止指令重排，防止指令重排要靠内存屏障。</p>
<p>屏障指令的统称叫做内存屏障，也叫内存栅栏， 就好比将在指令与指令边界驻扎栅栏，一方的指令无法跨越栅栏来到另一方。 内存屏障可以禁止指令重排序，内存屏障之前的写操作时，强制刷入内存；内存屏障之后的读操作可以读取之前的写操作的值，进而实现可见性。</p>
<p>内存屏障的指令分为四类：<br><strong>LoadLoad</strong>： 确保LoadLoad指令之前的Load指令的执行，先于LoadLoad指令之后的Load指令及其后续的load指令。(Load1 -&gt; LoadLoad -&gt; Load2)</p>
<p><strong>StoreStore</strong>： 确保StoreStore指令之前的Store指令的执行，先于StoreStore指令之后的Store指令及其后续的Store指令。(Store1 -&gt; StoreStore -&gt; Store2)</p>
<p><strong>LoadStore</strong>：确保LoadStore指令之前的Load指令的执行，先于LoadStore指令之后的Store指令及其后续的Store指令。(Load1 -&gt; LoadStore -&gt; Store2)</p>
<p><strong>StoreLoad</strong>：确保StoreLoad指令之前的所有内存指令(load，store)执行，先于StoreLoad指令之后的所有内存指令。(Store1 -&gt; StoreLoad -&gt; Load2)</p>
<h2 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a>CAS</h2><p>有序性和可见性可以通过volatile解决，原子性就需要用锁解决了。针对单个变量操作的话，还可以用CAS来保证原子性。CAS是一种乐观锁，更轻量高效，基于比较交换算法（Compare and swap）来解决线程冲突的。</p>
<p>原理就是会将内存位置的值与预期原值进行比较，如果一致，则说明无其他线程修改，处理器会自动将此位置的值更新为新值。反之则不处理。</p>
<p>CAS操作底层使用Unsafe类实现，Unsafe通过调用<a href="https://github.com/JetBrains/jdk8u_hotspot/blob/8u152/src/share/vm/prims/unsafe.cpp#L1229">本地方法</a>，调用到了C++中的<a href="https://github.com/JetBrains/jdk8u_hotspot/blob/8u152/src/share/vm/prims/unsafe.cpp#L1233">Atomic::cmpxchg</a>，这个调用了Atomic中的cmpxchg函数来比较交换，在这个函数里又调用了它的重载函数，这个会在预编译期间决定调用哪个平台的重载函数（目录：src/os_cpu），比如说windows系统就会调用<a href="https://github.com/JetBrains/jdk8u_hotspot/blob/8u152/src/os_cpu/windows_x86/vm/atomic_windows_x86.inline.hpp#L216">这一段汇编</a>, 最终通过汇编底层调用了处理器提供的CMPXCHG指令实现。</p>
<p>CAS的操作可能失败，失败后会一直自旋做CAS操作，直到成功为止。</p>
<p>CAS能无锁实现原子性，但也有一定缺陷：</p>
<ol>
<li>ABA问题：一个值从A到B又到A，CAS判断上虽然没问题，但还是不够安全，这个可以通过邮戳类解决。</li>
<li>自旋消耗CPU: 在高并发对同一变量频繁操作时，失败概率增加，重试次数增多导致CPU消耗增加。</li>
<li>只能保证单一共享变量的原子性：多个共享变量的原子性还是只能通过锁解决。</li>
</ol>
<p>Java需要通过JNI来访问底层系统，CAS使用的Unsafe就是个后门，可以像C++一样直接操作内存，其在sun.misc包中。Unsafe的getAndAddInt(this, valueOffset, 1)中的valueOffset就是内存偏移地址，直接通过内存操作数据。CAS是一个系统原语，是系统规定的原子指令，所以执行过程中不允许被中断，所以也不会有数据不一致的问题。</p>
<p>AtomicInteger源码分析：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1. 创建原子类，调用incrementAndGet方法</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        AtomicInteger atomicInteger = <span class="keyword">new</span> AtomicInteger();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//从此处点进去分析</span></span><br><span class="line">        atomicInteger.incrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2. 点进去调用了unsafe的获取并增加的方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">incrementAndGet</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">//传入了当前原子类，valueOffset是此数据在内存中的偏移量，1就是需要增加的量。</span></span><br><span class="line">    <span class="keyword">return</span> unsafe.getAndAddInt(<span class="keyword">this</span>, valueOffset, <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//3. unsafe中通过do while方式自旋，只有在this.compareAndSwapInt调用成功后才跳出自旋</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">getAndAddInt</span><span class="params">(Object atomicObj, <span class="keyword">long</span> valueOffset, <span class="keyword">int</span> addCount)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> var5;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="comment">//通过偏移量获取到原子类中的值，然后调用unsafe的native方法compareAndSwapInt</span></span><br><span class="line">        <span class="comment">//compareAndSwapInt的意思是传入预期值var5, 如果主内存中var5没有被修改到，</span></span><br><span class="line">        <span class="comment">//那么我就将var5 + addCount更新进去，如果被修改到了，那就是返回false了，while</span></span><br><span class="line">        <span class="comment">//还会一直自旋下去。</span></span><br><span class="line">        var5 = <span class="keyword">this</span>.getIntVolatile(atomicObj, valueOffset);</span><br><span class="line">    &#125; <span class="keyword">while</span>(!<span class="keyword">this</span>.compareAndSwapInt(atomicObj, valueOffset, var5, var5 + addCount));</span><br><span class="line">    <span class="keyword">return</span> var5;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>如何解决ABA的问题：<br>使用原子邮戳引用类，增加一个版本号机制，比较不再依赖原始数据，类似数据库中的version字段。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        AtomicStampedReference stampedReference = <span class="keyword">new</span> AtomicStampedReference&lt;&gt;(<span class="number">100</span>, <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">boolean</span> b = stampedReference.compareAndSet(<span class="number">100</span>, <span class="number">1001</span>, stampedReference.getStamp(), stampedReference.getStamp()+<span class="number">1</span>);</span><br><span class="line">        System.out.println(b);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="原子操作类"><a href="#原子操作类" class="headerlink" title="原子操作类"></a>原子操作类</h2><h3 id="基本类型原子类"><a href="#基本类型原子类" class="headerlink" title="基本类型原子类"></a>基本类型原子类</h3><p>AtomicInteger代码实现，AtomicBoolean和AtomicLong类似。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        AtomicInteger atomicInteger = <span class="keyword">new</span> AtomicInteger();</span><br><span class="line">        System.out.println(<span class="string">&quot;获取atomicInteger当前的值：&quot;</span> + atomicInteger.get());</span><br><span class="line">        System.out.println(<span class="string">&quot;获取atomicInteger当前的值并设置新的值：&quot;</span> + atomicInteger.getAndSet(<span class="number">3</span>));</span><br><span class="line">        System.out.println(<span class="string">&quot;获取atomicInteger当前的值并自增：&quot;</span>  + atomicInteger.getAndIncrement());</span><br><span class="line">        System.out.println(<span class="string">&quot;获取atomicInteger当前的值并自减：&quot;</span> + atomicInteger.getAndDecrement());</span><br><span class="line">        System.out.println(<span class="string">&quot;获取atomicInteger当前的值并加上预期的值：&quot;</span> + atomicInteger.getAndAdd(<span class="number">100</span>));</span><br><span class="line">        System.out.println(<span class="string">&quot;如何符合预期值便原子设置新的值进去：&quot;</span> + atomicInteger.compareAndSet(<span class="number">1</span>, <span class="number">100</span>));</span><br><span class="line">        System.out.println(<span class="string">&quot;如何符合预期值便原子设置新的值进去：&quot;</span> + atomicInteger.compareAndSet(<span class="number">103</span>, <span class="number">100</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="数组类型原子类"><a href="#数组类型原子类" class="headerlink" title="数组类型原子类"></a>数组类型原子类</h3><p>AtomicIntegerArray代码实现，AtomicLongArray和AtomicReferenceArray类似。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        AtomicIntegerArray atomicIntegerArray = <span class="keyword">new</span> AtomicIntegerArray(<span class="number">10</span>);</span><br><span class="line">        atomicIntegerArray.set(<span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">        atomicIntegerArray.set(<span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">        atomicIntegerArray.set(<span class="number">2</span>, <span class="number">2</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;打印输出：&quot;</span> + atomicIntegerArray);</span><br><span class="line">        System.out.println(<span class="string">&quot;获取index为0的元素：&quot;</span> + atomicIntegerArray.get(<span class="number">0</span>));</span><br><span class="line">        System.out.println(<span class="string">&quot;对index为0的元素获取并递增：&quot;</span> + atomicIntegerArray.getAndIncrement(<span class="number">0</span>));</span><br><span class="line">        System.out.println(<span class="string">&quot;对index为0的元素预期值为1的时候更新为100：&quot;</span> + atomicIntegerArray.compareAndSet(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="引用类型原子类"><a href="#引用类型原子类" class="headerlink" title="引用类型原子类"></a>引用类型原子类</h3><ol>
<li>AtomicReference: 可以包装一个自定义的对象，我们可以通过这个对象来做CAS操作。</li>
<li>AtomicStampedReference: 带有邮戳版本的原子应用类，可以解决ABA的问题。</li>
<li>AtomicMarkableReference：就是一个将版本号简化为true和false的类，标记这个对象是否修改过。</li>
</ol>
<h3 id="对象的属性修改原子类"><a href="#对象的属性修改原子类" class="headerlink" title="对象的属性修改原子类"></a>对象的属性修改原子类</h3><p>我们在使用引用类型原子类AtomicReference时，锁定的是整个对象，有时候就只想锁定对象里的某一个字段怎么办呢，那么就要用属性修改原子类了。有仨：AtomicIntegerFieldUpdater，AtomicLongFieldUpdater，AtomicReferenceFieldUpdater.</p>
<p>这样就能以一种线程安全的方式操作非线程安全对象内的某些字段了。</p>
<p>使用要求：更新的对象属性必须使用public volatile修饰，因为对象的属性修改类型原子类都是抽象类，所以每次使用都必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。</p>
<p>一个例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AtomicUpdaterDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        BankAccount bankAccount = <span class="keyword">new</span> BankAccount();</span><br><span class="line">        CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(<span class="number">10</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">new</span> Thread(() -&gt; &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">1000</span>; j++) &#123;</span><br><span class="line">                    bankAccount.addMoney(bankAccount);</span><br><span class="line">                &#125;</span><br><span class="line">                countDownLatch.countDown();</span><br><span class="line">            &#125;).start();</span><br><span class="line">        &#125;</span><br><span class="line">        countDownLatch.await();</span><br><span class="line">        System.out.println(bankAccount.money);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BankAccount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">volatile</span> <span class="keyword">int</span> money = <span class="number">100</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过AtomicIntegerFieldUpdater创建更新类，指定类名和字段，就能绑定到money字段。</span></span><br><span class="line">    AtomicIntegerFieldUpdater&lt;BankAccount&gt; accountAtomicIntegerFieldUpdater </span><br><span class="line">        = AtomicIntegerFieldUpdater.newUpdater(BankAccount.class, <span class="string">&quot;money&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//自增操作</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addMoney</span><span class="params">(BankAccount bankAccount)</span> </span>&#123;</span><br><span class="line">        accountAtomicIntegerFieldUpdater.incrementAndGet(bankAccount);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="原子操作增强类LongAdder等"><a href="#原子操作增强类LongAdder等" class="headerlink" title="原子操作增强类LongAdder等"></a>原子操作增强类LongAdder等</h3><p>原子操作增强类有LongAdder，LongAccumulator，DoubleAdder，DoubleAccumulator。具体来分析LongAdder。</p>
<p>LongAdder和AtomicLong相比，强就强在计数的性能上。LongAdder专注于计数，初始值默认为0还无法设置值，只能清零。在高并发场景下，LongAdder的计数性能会好很多。</p>
<p>原因是AtomicLong是在自旋CAS的时候会消耗CPU，并发量大的话CPU很容易打满，而LongAdder是分段治之的思想，将value值分为多个cell，当多线程访问这个value的时候通过hash算法匹配到其中一个cell，在求和的时候就将所有的cell累加起来。这样分散了资源竞争，降低了CPU的开销。</p>
<p>//LongAdder源码分析 TODO</p>
<h2 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h2><p>ThreadLocal提供在线程内存储变量的功能，然后在单个线程中可以共享和设置这些变量。变量在线程之间互相隔离，互不影响。</p>
<p>使用上：我们可以通过threadLocal.set(value)来设置一个值，然后通过threadLocal.get()获取这个值。</p>
<p>原理：就是每个Thread内部都拥有一份ThreadLocalMap，Map中存储了一个Entry数组，这个Entry以threadLocal对象本身为key，以值为value。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//threadLocal.set(value)点进去的源码</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(T value)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1. 获取到当前线程</span></span><br><span class="line">    Thread t = Thread.currentThread();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2. 直接从当前线程中拿到ThreadLocalMap这个map</span></span><br><span class="line">    <span class="comment">// 如果不为空直接设置进去，为空则创建新的</span></span><br><span class="line">    ThreadLocalMap map = getMap(t);</span><br><span class="line">    <span class="keyword">if</span> (map != <span class="keyword">null</span>)</span><br><span class="line">        map.set(<span class="keyword">this</span>, value);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        createMap(t, value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(ThreadLocal&lt;?&gt; key, Object value)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//1. 获取到table和table的长度</span></span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//2. 通过当前threadLocal的hash值与长度算出一个数组下标</span></span><br><span class="line">    <span class="keyword">int</span> i = key.threadLocalHashCode &amp; (len-<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//3. 通过for循环获取到下标不为null的元素</span></span><br><span class="line">    <span class="keyword">for</span> (Entry e = tab[i]; e != <span class="keyword">null</span>; e = tab[i = nextIndex(i, len)]) &#123;</span><br><span class="line">        <span class="comment">//4. 拿到后再次取出key来，如果是同一个threadLocal就直接将value设置进去</span></span><br><span class="line">        ThreadLocal&lt;?&gt; k = e.get();</span><br><span class="line">        <span class="keyword">if</span> (k == key) &#123;</span><br><span class="line">            e.value = value;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5. 如果获取的key是个null，那就替换一下</span></span><br><span class="line">        <span class="keyword">if</span> (k == <span class="keyword">null</span>) &#123;</span><br><span class="line">            replaceStaleEntry(key, value, i);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//4. 如果当前table内没有当前threadLocal为key的，就创建一个新的table元素并设置进去</span></span><br><span class="line">    tab[i] = <span class="keyword">new</span> Entry(key, value);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//5. size增加，并且清理一些槽位，并且如果size大于了阈值就扩容</span></span><br><span class="line">    <span class="keyword">int</span> sz = ++size;</span><br><span class="line">    <span class="keyword">if</span> (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)</span><br><span class="line">        rehash();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="强软弱虚四大引用"><a href="#强软弱虚四大引用" class="headerlink" title="强软弱虚四大引用"></a>强软弱虚四大引用</h3><p>强引用：JVM内存回收时，就算OOM也不会去回收强引用对象，即使该对象永远都不会被用到。这是内存泄露的主要原因之一。<br>软引用：使用java.lang.ref.SoftReference实现，系统内存足够时不回收，一旦内存不足时就被回收。<br>弱引用：使用java.lang.ref.WeakReference实现，只要GC一运行就回收，不论内存是否足够。<br>虚引用：使用java.lang.ref.PhantomReference实现，其不会决定对象的生命周期，如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。它不能单独使用也不能通过它访问对象，虚引用必须和引用队列 (ReferenceQueue)联合使用。虚引用的主要作用是跟踪对象被垃圾回收的状态。 仅仅是提供了一种确保对象被 finalize以后，做某些事情的机制。 PhantomReference的get方法总是返回null，因此无法访问对应的引用对象。</p>
<h3 id="ThreadLocal的内存泄露问题"><a href="#ThreadLocal的内存泄露问题" class="headerlink" title="ThreadLocal的内存泄露问题"></a>ThreadLocal的内存泄露问题</h3><p>内存泄漏的概念：不再使用的对象或者变量占用的内存不能被回收，就是内存泄露。</p>
<p>在ThreadLocal中的Entry是弱引用的，大概率减少了内存泄露的风险。当ThreadLocal在栈中使用完了，销毁之后，ThreadLocalMap里的key引用在GC后也会被回收，如果是强引用的话，就会导致key指向的ThreadLocal对象不能被回收。</p>
<p>此时key就为null了，也有问题，不过当我们在调用get，set或remove方法时，就会去尝试删除key为null的entry，可以释放value对象占用的内存。所以，尽量要在不使用某个ThreadLocal对象后，手动调用remove方法去删除它。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>JUC</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JUC</tag>
      </tags>
  </entry>
  <entry>
    <title>CDH基本环境搭建</title>
    <url>/2021/06/01/2.bigdata/build/CDH%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h2 id="基础简介"><a href="#基础简介" class="headerlink" title="基础简介"></a>基础简介</h2><p>版本：Cloudera Manager：6.2.1 CDH：6.2.1<br>CDH优点：可视化自动部署与配置，一键集成多种组件<br>CDH简介：CDH是Cloudera维护的稳定Hadoop技术栈发行版，其灵活，安全，可扩展性高，高可用，兼容性好。<br>CM简介：Cloudra Manager是一个web操作平台，可以借助CDH极简安装多种Hadoop框架。</p>
<span id="more"></span>

<h2 id="基础环境准备"><a href="#基础环境准备" class="headerlink" title="基础环境准备"></a>基础环境准备</h2><h3 id="1-配置三台机器hostname和映射关系"><a href="#1-配置三台机器hostname和映射关系" class="headerlink" title="1.配置三台机器hostname和映射关系"></a>1.配置三台机器hostname和映射关系</h3><p>修改hostname</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看当前hostname主机名</span></span><br><span class="line">hostname</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法一：命令修改主机名（无需重启只要开启新会话窗口就可更新）</span></span><br><span class="line">hostnamectl set-hostname hadoop001</span><br><span class="line">hostnamectl set-hostname hadoop002</span><br><span class="line">hostnamectl set-hostname hadoop003</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法二：编辑文件修改主机名（需要重启机器）</span></span><br><span class="line">vim /etc/hostname</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分别在三台机器修改文件内容为如下</span></span><br><span class="line">hadoop001</span><br><span class="line">hadoop002</span><br><span class="line">hadoop003</span><br><span class="line"></span><br><span class="line"><span class="comment">#重启机器</span></span><br><span class="line">reboot </span><br></pre></td></tr></table></figure>

<p>添加映射关系</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 编辑文件</span></span><br><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加如下内容</span></span><br><span class="line">第一台机器IP hadoop001</span><br><span class="line">第二台机器IP hadoop002</span><br><span class="line">第三台机器IP hadoop003</span><br></pre></td></tr></table></figure>

<h3 id="2-配置SSH免密登录"><a href="#2-配置SSH免密登录" class="headerlink" title="2.配置SSH免密登录"></a>2.配置SSH免密登录</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 分别在三台机器上执行如下命令</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#生成公私钥命令，直接三个回车</span></span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"></span><br><span class="line"><span class="comment">#分别在三台机器上执行如下三个命令，共执行九次</span></span><br><span class="line">ssh-copy-id hadoop001</span><br><span class="line">ssh-copy-id hadoop002</span><br><span class="line">ssh-copy-id hadoop003</span><br></pre></td></tr></table></figure>

<h3 id="3-关闭一些配置"><a href="#3-关闭一些配置" class="headerlink" title="3.关闭一些配置"></a>3.关闭一些配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#关闭防火墙</span></span><br><span class="line">systemctl stop firewalld </span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭Selinux</span></span><br><span class="line">setenforce 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑如下文件将SELINUX=enforcing改为SELINUX=disabled</span></span><br><span class="line">vim /etc/selinux/config</span><br><span class="line">SELINUX=disabled</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启生效</span></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure>
<p>附：如果是云服务器，则还需要在安全组内添加白名单，如果机器安装了一些Linux管理面板，也有可能需要在Liunx面板中的安全组关闭一次。</p>
<h2 id="Cloudra-Manager环境安装"><a href="#Cloudra-Manager环境安装" class="headerlink" title="Cloudra Manager环境安装"></a>Cloudra Manager环境安装</h2><h3 id="0-Linux机器安装基础依赖包"><a href="#0-Linux机器安装基础依赖包" class="headerlink" title="0.Linux机器安装基础依赖包"></a>0.Linux机器安装基础依赖包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y cyrus-sasl-plain cyrus-sasl-gssapi portmap fuse-libs bind-utils libxslt fuse</span><br><span class="line">yum install -y /lib/lsb/init-functions createrepo deltarpm python-deltarpm</span><br><span class="line">yum install -y mod_ssl openssl-devel python-psycopg2 MySQL-python</span><br><span class="line">yum install -y httpd</span><br><span class="line">yum install -y createrepo</span><br></pre></td></tr></table></figure>

<h3 id="1-下载CDH和CM相关安装包"><a href="#1-下载CDH和CM相关安装包" class="headerlink" title="1.下载CDH和CM相关安装包"></a>1.下载CDH和CM相关安装包</h3><p>下载地址：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 6.3.3版本后开始收费，现在下载都需要订阅了，所以测试时就无法从此链接下载了，需要找其他路径去下载</span><br><span class="line">https://archive.cloudera.com/cdh6/6.2.1/parcels/</span><br><span class="line">https://archive.cloudera.com/cm6/6.2.1/redhat7/yum/RPMS/x86_64/</span><br><span class="line"></span><br><span class="line"># 下载的文件如下</span><br><span class="line">cloudera-manager-agent-6.2.1-1426065.el7.x86_64.rpm</span><br><span class="line">cloudera-manager-daemons-6.2.1-1426065.el7.x86_64.rpm</span><br><span class="line">cloudera-manager-server-6.2.1-1426065.el7.x86_64.rpm</span><br><span class="line">cloudera-manager-server-db-2-6.2.1-1426065.el7.x86_64.rpm</span><br><span class="line">enterprise-debuginfo-6.2.1-1426065.el7.x86_64.rpm</span><br><span class="line">oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm</span><br><span class="line"></span><br><span class="line">CDH-6.2.1-1.cdh6.2.1.p0.1425774-el7.parcel</span><br><span class="line">CDH-6.2.1-1.cdh6.2.1.p0.1425774-el7.parcel.sha1</span><br><span class="line">CDH-6.2.1-1.cdh6.2.1.p0.1425774-el7.parcel.sha256</span><br><span class="line"></span><br><span class="line">allkeys.asc</span><br></pre></td></tr></table></figure>

<h3 id="2-搭建本地yum源"><a href="#2-搭建本地yum源" class="headerlink" title="2.搭建本地yum源"></a>2.搭建本地yum源</h3><p>启动httpd服务并上传rpm文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启动apache httpd服务</span></span><br><span class="line">systemctl start httpd.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 到httpd服务器目录下创建一个目录</span></span><br><span class="line">mkdir -p /var/www/html/cm6/6.2.1/redhat7/yum/RPMS/x86_64/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将如下文件全部上传到 x86_64目录下</span></span><br><span class="line">cloudera-manager-agent-6.2.1-1426065.el7.x86_64.rpm</span><br><span class="line">cloudera-manager-daemons-6.2.1-1426065.el7.x86_64.rpm</span><br><span class="line">cloudera-manager-server-6.2.1-1426065.el7.x86_64.rpm</span><br><span class="line">cloudera-manager-server-db-2-6.2.1-1426065.el7.x86_64.rpm</span><br><span class="line">enterprise-debuginfo-6.2.1-1426065.el7.x86_64.rpm</span><br><span class="line">oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将如下文件拷贝到/var/www/html/cm6/6.2.1/下</span></span><br><span class="line">allkeys.asc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 访问测试是否能访问到文件</span></span><br><span class="line">http://hadoop001/cm6/6.2.1/redhat7/yum/RPMS/x86_64/</span><br></pre></td></tr></table></figure>

<p>生成repodata目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /var/www/html/cm6/6.2.1/redhat7/yum</span><br><span class="line">createrepo .</span><br></pre></td></tr></table></figure>

<p>配置yum源</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/yum.repos.d/cloudera-manager.repo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 填写如下内容</span></span><br><span class="line">[cloudera-manager]</span><br><span class="line">name=Cloudera Manager</span><br><span class="line">baseurl=http://hadoop001/cm6/6.2.1/redhat7/yum/</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行命令清理刷新</span></span><br><span class="line">yum clean all</span><br><span class="line">yum list | grep cloudera</span><br></pre></td></tr></table></figure>

<p>如果在yum源中添加了新包，需要删除之前的repodata文件后重新生成，并重启httpd服务，再执行<code>yum clean all</code>清除缓存。</p>
<h3 id="3-创建用于管理集群的用户"><a href="#3-创建用于管理集群的用户" class="headerlink" title="3.创建用于管理集群的用户"></a>3.创建用于管理集群的用户</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 增加用户</span></span><br><span class="line">useradd cloudera-scm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给用户设置密码</span></span><br><span class="line">passwd cloudera-scm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给root权限并免密</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;cloudera-scm ALL=(root) NOPASSWD:ALL&quot;</span> &gt;&gt; /etc/sudoers</span><br></pre></td></tr></table></figure>

<h3 id="4-安装MySQL服务"><a href="#4-安装MySQL服务" class="headerlink" title="4.安装MySQL服务"></a>4.安装MySQL服务</h3><p>安装执行过程如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 卸载自带</span></span><br><span class="line">rpm -qa | grep -i -E mysql\|mariadb | xargs -n1 sudo rpm -e --nodeps</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载如下MySQL相关文件</span></span><br><span class="line">01_mysql-community-common-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">02_mysql-community-libs-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">03_mysql-community-libs-compat-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">04_mysql-community-client-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">05_mysql-community-server-5.7.16-1.el7.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始进行安装</span></span><br><span class="line">sudo rpm -ivh 01_mysql-community-common-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">sudo rpm -ivh 02_mysql-community-libs-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">sudo rpm -ivh 03_mysql-community-libs-compat-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">sudo rpm -ivh 04_mysql-community-client-5.7.16-1.el7.x86_64.rpm</span><br><span class="line">sudo rpm -ivh 05_mysql-community-server-5.7.16-1.el7.x86_64.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果有包缺失就对应执行如下</span></span><br><span class="line">yum install net-tools</span><br><span class="line">yum install perl</span><br><span class="line">yum install libaio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动命令</span></span><br><span class="line">sudo systemctl start mysqld</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看初始化的密码</span></span><br><span class="line">sudo cat /var/<span class="built_in">log</span>/mysqld.log | grep password</span><br></pre></td></tr></table></figure>

<p>密码配置与账号配置</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 输入密码登录MySQL</span></span><br><span class="line">mysql <span class="operator">-</span>uroot <span class="operator">-</span>p</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 更改密码策略，测试环境用简单密码</span></span><br><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> validate_password_length<span class="operator">=</span><span class="number">4</span>;</span><br><span class="line"><span class="keyword">set</span> <span class="keyword">global</span> validate_password_policy<span class="operator">=</span><span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 设置密码</span></span><br><span class="line"><span class="keyword">set</span> password<span class="operator">=</span>password(&quot;123456&quot;);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建scm数据库</span></span><br><span class="line"><span class="keyword">create</span> database scm <span class="keyword">DEFAULT</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> PRIVILEGES <span class="keyword">on</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;123456&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> PRIVILEGES <span class="keyword">on</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;123456&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br><span class="line"><span class="keyword">grant</span> <span class="keyword">all</span> PRIVILEGES <span class="keyword">on</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;root&#x27;</span>@<span class="string">&#x27;hadoop001&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;123456&#x27;</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> OPTION;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>

<h2 id="安装Cloudera-Server服务"><a href="#安装Cloudera-Server服务" class="headerlink" title="安装Cloudera Server服务"></a>安装Cloudera Server服务</h2><h3 id="1-通过搭建好的yum源安装服务"><a href="#1-通过搭建好的yum源安装服务" class="headerlink" title="1.通过搭建好的yum源安装服务"></a>1.通过搭建好的yum源安装服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y oracle-j2sdk1.8-1.8.0+update181-1.x86_64</span><br><span class="line">yum install -y enterprise-debuginfo-6.2.1-1426065.el7.x86_64</span><br><span class="line">yum install -y cloudera-manager-server-6.2.1-1426065.el7.x86_64</span><br><span class="line">yum install -y cloudera-manager-server-db-2-6.2.1-1426065.el7.x86_64</span><br></pre></td></tr></table></figure>

<h3 id="2-配置元数据库，执行预备脚本"><a href="#2-配置元数据库，执行预备脚本" class="headerlink" title="2.配置元数据库，执行预备脚本"></a>2.配置元数据库，执行预备脚本</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 先将MySQL驱动拷贝到cm的lib目录下</span></span><br><span class="line">cp /opt/software/mysql-connector-java-5.1.40.jar /opt/cloudera/cm/lib</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行scm_prepare_database.sh脚本</span></span><br><span class="line">/opt/cloudera/cm/schema/scm_prepare_database.sh -h localhost mysql scm root 123456</span><br></pre></td></tr></table></figure>

<h3 id="3-启动cm-server进程"><a href="#3-启动cm-server进程" class="headerlink" title="3.启动cm server进程"></a>3.启动cm server进程</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启动命令</span></span><br><span class="line">systemctl start cloudera-scm-server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看启动状态</span></span><br><span class="line">systemctl status cloudera-scm-server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看日志</span></span><br><span class="line">tail -f /var/<span class="built_in">log</span>/cloudera-scm-server/cloudera-scm-server.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看端口</span></span><br><span class="line">netstat -anp | grep 7180</span><br></pre></td></tr></table></figure>

<h3 id="4-配置本地parcel包"><a href="#4-配置本地parcel包" class="headerlink" title="4.配置本地parcel包"></a>4.配置本地parcel包</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在数据库初始化后，将parcel文件放到/opt/cloudera/parcel-repo中</span></span><br><span class="line">cp /opt/software/CDH-6.2.1-1.cdh6.2.1.p0.1425774-el7.parcel /opt/cloudera/parcel-repo</span><br><span class="line">cp /opt/software/CDH-6.2.1-1.cdh6.2.1.p0.1425774-el7.parcel.sha1 /opt/cloudera/parcel-repo</span><br><span class="line">cp /opt/software/CDH-6.2.1-1.cdh6.2.1.p0.1425774-el7.parcel.sha256 /opt/cloudera/parcel-repo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重命名密钥文件</span></span><br><span class="line">mv CDH-6.2.1-1.cdh6.2.1.p0.1425774-el7.parcel.sha1 CDH-6.2.1-1.cdh6.2.1.p0.1425774-el7.parcel.sha</span><br></pre></td></tr></table></figure>

<h3 id="5-配置swappiness和透明化"><a href="#5-配置swappiness和透明化" class="headerlink" title="5.配置swappiness和透明化"></a>5.配置swappiness和透明化</h3><p>透明化配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看透明页面是否开启</span></span><br><span class="line">cat /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">[always] madvise never <span class="comment">#表示已经启用</span></span><br><span class="line">always madvise [never] <span class="comment">#表示已经关闭</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行命令进行关闭(临时生效)</span></span><br><span class="line"><span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line"><span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行命令进行关闭(永久生效)</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag&quot;</span> &gt;&gt; /etc/rc.local</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&quot;</span> &gt;&gt; /etc/rc.local</span><br></pre></td></tr></table></figure>

<p>swappiness配置，内核参数为vm.swappiness，值范围是0-100，表示系统何时开始交换物理内存与虚拟内存。举例：系统内存为100G，vm.swappiness为10，则表示系统内存在使用到 <code>100G * [ (100 - 10) / 100 ] = 90G</code> 的时候才进行物理内存和虚拟内存的交换，这个会影响性能，所以建议区间是1-10。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 临时生效</span></span><br><span class="line">sysctl -w vm.swappiness=10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 永久生效</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;vm.swappiness=10&quot;</span> &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure>

<h2 id="访问WEB-UI界面进行安装操作"><a href="#访问WEB-UI界面进行安装操作" class="headerlink" title="访问WEB-UI界面进行安装操作"></a>访问WEB-UI界面进行安装操作</h2><h3 id="1-进入界面"><a href="#1-进入界面" class="headerlink" title="1. 进入界面"></a>1. 进入界面</h3><p>访问地址：<a href="http://hadoop001:7180/cmf/login">http://hadoop001:7180/cmf/login</a><br>账号密码: admin</p>
<p>登录后进入欢迎界面，点击Continue下一步<br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/cdh_install_1.png"></p>
<h3 id="2-点击yes同意，再点击Continue下一步"><a href="#2-点击yes同意，再点击Continue下一步" class="headerlink" title="2. 点击yes同意，再点击Continue下一步"></a>2. 点击yes同意，再点击Continue下一步</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/cdh_install_2.png"></p>
<h3 id="3-测试环境选择Cloudera-Express-Free免费版本，然后再点击Continue下一步"><a href="#3-测试环境选择Cloudera-Express-Free免费版本，然后再点击Continue下一步" class="headerlink" title="3. 测试环境选择Cloudera Express Free免费版本，然后再点击Continue下一步"></a>3. 测试环境选择Cloudera Express Free免费版本，然后再点击Continue下一步</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/cdh_install_3.png"></p>
<h3 id="4-给我们的集群取一个名字"><a href="#4-给我们的集群取一个名字" class="headerlink" title="4. 给我们的集群取一个名字"></a>4. 给我们的集群取一个名字</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/cdh_install_4.png"></p>
<h3 id="5-在Hostname中填入主机名搜索，然后勾选搜索到的结果再点击Continue下一步"><a href="#5-在Hostname中填入主机名搜索，然后勾选搜索到的结果再点击Continue下一步" class="headerlink" title="5. 在Hostname中填入主机名搜索，然后勾选搜索到的结果再点击Continue下一步"></a>5. 在Hostname中填入主机名搜索，然后勾选搜索到的结果再点击Continue下一步</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/cdh_install_5.png"></p>
<h3 id="6-配置本地仓库"><a href="#6-配置本地仓库" class="headerlink" title="6. 配置本地仓库"></a>6. 配置本地仓库</h3><p>此处Custom Repository选默认，为: <a href="http://hadoop001/cm6/6.2.1%EF%BC%8CCDH">http://hadoop001/cm6/6.2.1，CDH</a> Version此时是没有扫描到的，所以需要访问此链接(<a href="http://gf-hadoop001:7180/cmf/parcel/status)%E9%85%8D%E7%BD%AE%E4%B8%80%E4%B8%8B%60Parcel">http://gf-hadoop001:7180/cmf/parcel/status)配置一下`Parcel</a> Update Frequency 包更新周期`，可以配置为1分钟一次，安装的时候才能展示出来。安装成功后可以设置回一小时，其他选项都默认，再次点击Continue下一步<br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/cdh_install_6.png"></p>
<h3 id="7-此处勾选安装Oracle的JDK"><a href="#7-此处勾选安装Oracle的JDK" class="headerlink" title="7. 此处勾选安装Oracle的JDK"></a>7. 此处勾选安装Oracle的JDK</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/cdh_install_7.png"></p>
<h3 id="8-配置root的密码"><a href="#8-配置root的密码" class="headerlink" title="8. 配置root的密码"></a>8. 配置root的密码</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/cdh_install_8.png"></p>
<h3 id="9-开始等待agents的安装"><a href="#9-开始等待agents的安装" class="headerlink" title="9. 开始等待agents的安装"></a>9. 开始等待agents的安装</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/cdh_install_9.png"></p>
<h3 id="10-检查集群环境"><a href="#10-检查集群环境" class="headerlink" title="10. 检查集群环境"></a>10. 检查集群环境</h3><p>安装成功后检查集群的环境，先检查网络情况，但是因为此时安装的是单机环境，网络检查状态是有问题的，但是没关系先跳过。然后再是检查host环境，检查通过后选择<code>I understand the risks...</code> 再点击下一步。<br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/cdh_install_10.png"></p>
<p>这是上一步host检查的结果，如果我们没有配置swappiness和透明化，那么红框中的选项就会有异常。<br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/cdh_install_11.png"></p>
<h3 id="11-一键安装常用组件"><a href="#11-一键安装常用组件" class="headerlink" title="11. 一键安装常用组件"></a>11. 一键安装常用组件</h3><p>这一步可以一键安装一些常用组件，不安装则直接点返回，此时软件环境就已经安装成功了。<br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/cdh_install_12.png"></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>环境搭建</tag>
      </tags>
  </entry>
  <entry>
    <title>使用抢占式阿里云ECS构建短期测试环境</title>
    <url>/2021/06/01/2.bigdata/build/%E4%BD%BF%E7%94%A8%E6%8A%A2%E5%8D%A0%E5%BC%8F%E9%98%BF%E9%87%8C%E4%BA%91ECS%E6%9E%84%E5%BB%BA%E7%9F%AD%E6%9C%9F%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><p>在开发中，当业务完成，或是环境需要，一般都会在自己的机器上搭建一个或多个虚拟机，如果业务并发量小，环境组件少，占用内存少的话，那自己的机器还是能够运行成功。但是，如果业务量测试并发量大，如秒杀业务测试，环境组件多，占用内存大，自己的机器根本撑不住，所以此时，就需要去购买一些第三方服务器来测试了。可以使用阿里云的ECS云服务器，并使用<code>抢占式实例</code>来进行短期测试，三台8核16G的机器也就0.6元/小时。</p>
<span id="more"></span>


<h2 id="购买安装"><a href="#购买安装" class="headerlink" title="购买安装"></a>购买安装</h2><h3 id="1-注册登录阿里云，进入ECS界面"><a href="#1-注册登录阿里云，进入ECS界面" class="headerlink" title="1.注册登录阿里云，进入ECS界面"></a>1.注册登录阿里云，进入ECS界面</h3><p>注册登录后，需要实名认证，通过后就可以进入ECS界面准备购买云服务器了<br><a href="https://www.aliyun.com/activity/ambassador/share-gift/goods?taskCode=share618&amp;recordId=711202&amp;userCode=u47plryb">https://www.aliyun.com/activity/ambassador/share-gift/goods?taskCode=share618&amp;recordId=711202&amp;userCode=u47plryb</a><br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/aliyun-1.png"></p>
<h3 id="2-点击购买，选择配置"><a href="#2-点击购买，选择配置" class="headerlink" title="2.点击购买，选择配置"></a>2.点击购买，选择配置</h3><p>此处选择抢占式实例，地区不同价格也不同，选深圳便宜一些，我们此处测试选择一个折扣率为16%的4核16G机器，购买数量为3台，镜像选择CentOS7.6，也可以根据自己需求进行购买<br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/aliyun-2.png"><br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/aliyun-3.png"></p>
<h3 id="3-点击下一步，配置网络"><a href="#3-点击下一步，配置网络" class="headerlink" title="3.点击下一步，配置网络"></a>3.点击下一步，配置网络</h3><p>选择按使用流量计费，安全组选择一个可以让自己机器连接上的组，不存在则创建。（在测试时，可以先查询到自己的IP地址，在安全组再配置一个自己IP的全端口白名单组，那样测试起来比较方便，也不会被别人扫端口扫到而被入侵）<br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/aliyun-4.png"></p>
<h3 id="4-配置密码和主机名"><a href="#4-配置密码和主机名" class="headerlink" title="4.配置密码和主机名"></a>4.配置密码和主机名</h3><p>我们可以用密钥对，也可以用密码，此处选择密码，实例名称与主机名取<code>hadoop[001,3]</code>，这是ECS多机器的取名规则，默认从hadoop001开始，取三个，就是<code>hadoop001,hadoop002,hadoop003</code><br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/aliyun-5.png"></p>
<h3 id="5-此时我们就可以确认订单了，耗费0-493元-时"><a href="#5-此时我们就可以确认订单了，耗费0-493元-时" class="headerlink" title="5.此时我们就可以确认订单了，耗费0.493元/时"></a>5.此时我们就可以确认订单了，耗费0.493元/时</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/aliyun-6.png"></p>
<h3 id="6-最后能在控制台看到这三台机器了"><a href="#6-最后能在控制台看到这三台机器了" class="headerlink" title="6.最后能在控制台看到这三台机器了"></a>6.最后能在控制台看到这三台机器了</h3><p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/aliyun-7.png"></p>
]]></content>
      <categories>
        <category>大数据</category>
        <category>环境搭建</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>环境搭建</tag>
      </tags>
  </entry>
  <entry>
    <title>FlinkSQL与API极速入门</title>
    <url>/2021/06/10/2.bigdata/flink/FlinkSQL%E4%B8%8EAPI%E6%9E%81%E9%80%9F%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h2 id="Flink-SQL与API简介"><a href="#Flink-SQL与API简介" class="headerlink" title="Flink SQL与API简介"></a>Flink SQL与API简介</h2><p>简而言之，Flink API是一套查询API，可以将文件系统、Kafka队列等外部数据在Flink中映射成表结构，然后通过API进行查询。Flink SQL则是可以直接通过SQL语句进行查询统计。</p>
<p>官方文档地址：<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/">https://ci.apache.org/projects/flink/flink-docs-release-1.13/</a></p>
<span id="more"></span>

<h2 id="入门代码示例"><a href="#入门代码示例" class="headerlink" title="入门代码示例"></a>入门代码示例</h2><p>先创建一个Maven工程，然后在pom.xml中添加依赖：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-realtime-mall<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.whoiszxl<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-sql<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>$&#123;java.version&#125;<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>$&#123;java.version&#125;<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">flink.version</span>&gt;</span>1.12.0<span class="tag">&lt;/<span class="name">flink.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scala.version</span>&gt;</span>2.12<span class="tag">&lt;/<span class="name">scala.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hadoop.version</span>&gt;</span>3.1.3<span class="tag">&lt;/<span class="name">hadoop.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java_$&#123;scala.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka_$&#123;scala.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-jdbc_$&#123;scala.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-api-java-bridge_$&#123;scala.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-table-planner-blink_$&#123;scala.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-csv<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients_$&#123;scala.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.18.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>再创建一个测试数据：books.csv</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">西游记,吴承恩,28.00</span><br><span class="line">三国演义,罗贯中,13.00</span><br><span class="line">红楼梦,曹雪芹,12.00</span><br><span class="line">水浒传,施耐庵,11.00</span><br></pre></td></tr></table></figure>

<p>创建Java程序，从本地csv中读取文件映射成表，再通过API和SQL进行查询</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FileSystemApp</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String CSV_PATH = <span class="string">&quot;/opt/data/books.txt&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//1. 获取流环境执行上下文环境</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        <span class="comment">//2. 设置并行度，测试时设置为1</span></span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 设置Checkpoint检查点</span></span><br><span class="line">        env.enableCheckpointing(<span class="number">5000</span>, CheckpointingMode.EXACTLY_ONCE); <span class="comment">//检查点5秒一次，模式为精准一次性</span></span><br><span class="line">        env.getCheckpointConfig().setCheckpointTimeout(<span class="number">60000</span>); <span class="comment">//超时时间一分钟</span></span><br><span class="line">        StateBackend fsStateBackend = <span class="keyword">new</span> FsStateBackend(<span class="string">&quot;hdfs://hadoop001:8020/appName/flink/checkpoint&quot;</span>);</span><br><span class="line">        env.setStateBackend(fsStateBackend); <span class="comment">//checkpoint持久化到hdfs上</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 定义Table流环境的配置</span></span><br><span class="line">        EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">                .newInstance() <span class="comment">//创建实例</span></span><br><span class="line">                .useBlinkPlanner() <span class="comment">//使用Blink的计划器</span></span><br><span class="line">                .inStreamingMode() <span class="comment">//使用流处理模式, .inBatchMode()为批处理模式</span></span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5. 通过流上下文环境与table配置创建Table流环境</span></span><br><span class="line">        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env, settings);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6. 定义文件系统数据源 connect已经被定义为@Deprecated，建议使用executeSql通过DDL语言创建</span></span><br><span class="line">        tableEnv.connect(<span class="keyword">new</span> FileSystem().path(CSV_PATH))</span><br><span class="line">                .withFormat(<span class="keyword">new</span> Csv()) <span class="comment">//用CSV格式进行格式化</span></span><br><span class="line">                .withSchema( <span class="comment">//定义表结构</span></span><br><span class="line">                        <span class="keyword">new</span> Schema()</span><br><span class="line">                        .field(<span class="string">&quot;name&quot;</span>, DataTypes.STRING())</span><br><span class="line">                        .field(<span class="string">&quot;author&quot;</span>, DataTypes.STRING())</span><br><span class="line">                        .field(<span class="string">&quot;price&quot;</span>, DataTypes.DOUBLE())</span><br><span class="line">                ).createTemporaryTable(<span class="string">&quot;books_table&quot;</span>); <span class="comment">//创建临时表并赋名</span></span><br><span class="line"></span><br><span class="line">        Table resultTable = tableEnv.from(<span class="string">&quot;books_table&quot;</span>) <span class="comment">//指定从什么表查询</span></span><br><span class="line">                .select(Expressions.$(<span class="string">&quot;name&quot;</span>), <span class="comment">//需要查询什么字段</span></span><br><span class="line">                        Expressions.$(<span class="string">&quot;author&quot;</span>),</span><br><span class="line">                        Expressions.$(<span class="string">&quot;price&quot;</span>))</span><br><span class="line">                .where(Expressions.$(<span class="string">&quot;name&quot;</span>).isEqual(<span class="string">&quot;西游记&quot;</span>)); <span class="comment">//查询条件</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//7. 将表转流并输出</span></span><br><span class="line">        tableEnv.toAppendStream(resultTable, Book.class).print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//8. 使用SQL进行查询并输出</span></span><br><span class="line">        TableResult tableResult = tableEnv.executeSql(<span class="string">&quot;select name,author,price from books_table where price &gt; 12&quot;</span>);</span><br><span class="line">        tableResult.print();</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h2 id="Flink-SQL-连接Kakfa"><a href="#Flink-SQL-连接Kakfa" class="headerlink" title="Flink SQL 连接Kakfa"></a>Flink SQL 连接Kakfa</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaApp</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//1. 获取流环境执行上下文环境</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        <span class="comment">//2. 设置并行度，测试时设置为1</span></span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 设置Checkpoint检查点</span></span><br><span class="line">        env.enableCheckpointing(<span class="number">5000</span>, CheckpointingMode.EXACTLY_ONCE); <span class="comment">//检查点5秒一次，模式为精准一次性</span></span><br><span class="line">        env.getCheckpointConfig().setCheckpointTimeout(<span class="number">60000</span>); <span class="comment">//超时时间一分钟</span></span><br><span class="line">        StateBackend fsStateBackend = <span class="keyword">new</span> FsStateBackend(<span class="string">&quot;hdfs://hadoop001:8020/appName/flink/checkpoint&quot;</span>);</span><br><span class="line">        env.setStateBackend(fsStateBackend); <span class="comment">//checkpoint持久化到hdfs上</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 定义Table流环境的配置</span></span><br><span class="line">        EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">                .newInstance() <span class="comment">//创建实例</span></span><br><span class="line">                .useBlinkPlanner() <span class="comment">//使用Blink的计划器</span></span><br><span class="line">                .inStreamingMode() <span class="comment">//使用流处理模式, .inBatchMode()为批处理模式</span></span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5. 通过流上下文环境与table配置创建Table流环境</span></span><br><span class="line">        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env, settings);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6. 使用executeSql通过DDL语言创建</span></span><br><span class="line">        tableEnv.executeSql(<span class="string">&quot;CREATE TABLE books (&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    name STRING,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    author STRING,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    price DECIMAL(8,2),&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    ts TIMESTAMP(3),&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    WATERMARK FOR ts as ts - INTERVAL &#x27;5&#x27; SECOND&quot;</span> +</span><br><span class="line">                <span class="string">&quot;) WITH (&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;connector&#x27; = &#x27;kafka&#x27;,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;topic&#x27; = &#x27;books_topic&#x27;,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;scan.startup.mode&#x27; = &#x27;latest-offset&#x27;,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;properties.bootstrap.servers&#x27; = &#x27;hadoop001:9092&#x27;,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;format&#x27; = &#x27;json&#x27;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;)&quot;</span>);</span><br><span class="line"></span><br><span class="line">        TableResult tableResult = tableEnv.executeSql(<span class="string">&quot;select name,author,price from books where price &gt;= 13&quot;</span>);</span><br><span class="line">        tableResult.print();</span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>建表语句</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> books ( <span class="comment">-- 指定表名</span></span><br><span class="line">    name STRING, <span class="comment">-- 书籍名称字段</span></span><br><span class="line">    author STRING, <span class="comment">-- 书籍作者字段</span></span><br><span class="line">    price <span class="type">DECIMAL</span>(<span class="number">8</span>,<span class="number">2</span>), <span class="comment">-- 价格字段</span></span><br><span class="line">    ts <span class="type">TIMESTAMP</span>(<span class="number">3</span>), <span class="comment">-- eventTime 时间戳字段</span></span><br><span class="line">    WATERMARK <span class="keyword">FOR</span> ts <span class="keyword">as</span> ts <span class="operator">-</span> <span class="type">INTERVAL</span> <span class="string">&#x27;5&#x27;</span> <span class="keyword">SECOND</span> <span class="comment">-- 以ts创建watermark，允许5秒乱序</span></span><br><span class="line">    ) <span class="keyword">WITH</span> (</span><br><span class="line">    <span class="string">&#x27;connector&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;kafka&#x27;</span>, <span class="comment">-- 指定连接器为kafka</span></span><br><span class="line">    <span class="string">&#x27;topic&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;books_topic&#x27;</span>, <span class="comment">-- 指定数据源主题</span></span><br><span class="line">    <span class="string">&#x27;scan.startup.mode&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;latest-offset&#x27;</span>, <span class="comment">-- 从最新的offset开始消费</span></span><br><span class="line">    <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;hadoop001:9092&#x27;</span>, <span class="comment">-- 指定kafka地址</span></span><br><span class="line">    <span class="string">&#x27;format&#x27;</span> <span class="operator">=</span> <span class="string">&#x27;json&#x27;</span> <span class="comment">-- 指定消费的数据格式为json</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>当创建好Java程序后，首先先去kafka上创建一个主题</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kafka-topics --zookeeper hadoop001:2181 --create --replication-factor 3 --partitions 3 --topic books_topic</span><br></pre></td></tr></table></figure>

<p>此时再运行Java程序，再启动一个Kakfa生产者，发送消息进行测试，运行成功的话会在Java控制台输出结果</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 运行Kafka生产者</span></span><br><span class="line">kafka-console-producer --broker-list hadoop001:9092 --topic books_topic</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送消息，输入的数据price大于等于13的会在控制台输出</span></span><br><span class="line">&gt;&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;三国演义&quot;</span>, <span class="string">&quot;author&quot;</span>: <span class="string">&quot;罗贯中&quot;</span>, <span class="string">&quot;price&quot;</span>: 15.00&#125;</span><br><span class="line">&gt;&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;西游记&quot;</span>, <span class="string">&quot;author&quot;</span>: <span class="string">&quot;吴承恩&quot;</span>, <span class="string">&quot;price&quot;</span>: 20.00&#125;</span><br><span class="line">&gt;&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;百年孤独&quot;</span>, <span class="string">&quot;author&quot;</span>: <span class="string">&quot;马尔克斯&quot;</span>, <span class="string">&quot;price&quot;</span>: 13.00&#125;</span><br><span class="line">&gt;&#123;<span class="string">&quot;name&quot;</span>:<span class="string">&quot;白鹿原&quot;</span>, <span class="string">&quot;author&quot;</span>: <span class="string">&quot;陈忠实&quot;</span>, <span class="string">&quot;price&quot;</span>: 9.00&#125;</span><br></pre></td></tr></table></figure>

<h2 id="DataStream转Table"><a href="#DataStream转Table" class="headerlink" title="DataStream转Table"></a>DataStream转Table</h2><p>Flink消费Kafka的时候，有些数据是不适合直接转换为表的，比如说多层的JSON、CSV和行数据等。所以就可以先流式读取数据，然后再map转成实体，再将实体转换为表。</p>
<p>使用如下代码进行转换</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Table booksTable = tableEnv.fromDataStream(dataStream, <span class="string">&quot;name as bookName, author, price&quot;</span>);</span><br></pre></td></tr></table></figure>

<h2 id="创建临时视图"><a href="#创建临时视图" class="headerlink" title="创建临时视图"></a>创建临时视图</h2><p>View和Table的Schema完全相同，可以认为View和Table是等价的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//直接从数据流转换</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;booksView&quot;</span>, dataStream);</span><br><span class="line"></span><br><span class="line"><span class="comment">//从数据流转换并指定字段</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;booksView&quot;</span>, dataStream, <span class="string">&quot;name as bookName, author, price&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//基于Table创建视图</span></span><br><span class="line">tableEnv.createTemporaryView(<span class="string">&quot;booksView&quot;</span>, booksTable);</span><br></pre></td></tr></table></figure>

<h2 id="输出表"><a href="#输出表" class="headerlink" title="输出表"></a>输出表</h2><p>通过TableSink可以将数据输出到文件、数据库、消息队列等中。通过Table.insertInto()实现。</p>
<h3 id="1-输出到文件系统"><a href="#1-输出到文件系统" class="headerlink" title="1.输出到文件系统"></a>1.输出到文件系统</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaApp</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//1. 获取流环境执行上下文环境</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        <span class="comment">//2. 设置并行度，测试时设置为1</span></span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 设置Checkpoint检查点</span></span><br><span class="line">        env.enableCheckpointing(<span class="number">5000</span>, CheckpointingMode.EXACTLY_ONCE); <span class="comment">//检查点5秒一次，模式为精准一次性</span></span><br><span class="line">        env.getCheckpointConfig().setCheckpointTimeout(<span class="number">60000</span>); <span class="comment">//超时时间一分钟</span></span><br><span class="line">        StateBackend fsStateBackend = <span class="keyword">new</span> FsStateBackend(<span class="string">&quot;hdfs://hadoop001:8020/appName/flink/checkpoint&quot;</span>);</span><br><span class="line">        env.setStateBackend(fsStateBackend); <span class="comment">//checkpoint持久化到hdfs上</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 定义Table流环境的配置</span></span><br><span class="line">        EnvironmentSettings settings = EnvironmentSettings</span><br><span class="line">                .newInstance() <span class="comment">//创建实例</span></span><br><span class="line">                .useBlinkPlanner() <span class="comment">//使用Blink的计划器</span></span><br><span class="line">                .inStreamingMode() <span class="comment">//使用流处理模式, .inBatchMode()为批处理模式</span></span><br><span class="line">                .build();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//5. 通过流上下文环境与table配置创建Table流环境</span></span><br><span class="line">        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env, settings);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//6. 使用executeSql通过DDL语言创建源数据表</span></span><br><span class="line">        tableEnv.executeSql(<span class="string">&quot;CREATE TABLE books (&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    name STRING,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    author STRING,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    price DECIMAL(8,2),&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    ts TIMESTAMP(3),&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    WATERMARK FOR ts as ts - INTERVAL &#x27;5&#x27; SECOND&quot;</span> +</span><br><span class="line">                <span class="string">&quot;) WITH (&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;connector&#x27; = &#x27;kafka&#x27;,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;topic&#x27; = &#x27;books_topic&#x27;,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;scan.startup.mode&#x27; = &#x27;latest-offset&#x27;,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;properties.bootstrap.servers&#x27; = &#x27;hadoop001:9092&#x27;,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;format&#x27; = &#x27;json&#x27;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;)&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//7. 使用executeSql通过DDL语言创建输出数据表，指定为文件系统</span></span><br><span class="line">        tableEnv.executeSql(<span class="string">&quot;CREATE TABLE books_result (&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    name STRING,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    author STRING,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    price DECIMAL(8,2)&quot;</span> +</span><br><span class="line">                <span class="string">&quot;) WITH (&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;connector&#x27; = &#x27;filesystem&#x27;,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;sink.partition-commit.delay&#x27;=&#x27;1 h&#x27;,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;sink.partition-commit.policy.kind&#x27;=&#x27;success-file&#x27;,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;path&#x27; = &#x27;../books_result.csv&#x27;,&quot;</span> +</span><br><span class="line">                <span class="string">&quot;    &#x27;format&#x27; = &#x27;csv&#x27;&quot;</span> +</span><br><span class="line">                <span class="string">&quot;)&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//8. 直接执行insert 操作</span></span><br><span class="line">        tableEnv.executeSql(<span class="string">&quot;insert into books_result select name,author,price from books where price &gt;= 13&quot;</span>);</span><br><span class="line"></span><br><span class="line">        env.execute();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-输出到MySQL"><a href="#2-输出到MySQL" class="headerlink" title="2.输出到MySQL"></a>2.输出到MySQL</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">CREATE TABLE <span class="title">books</span> <span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">  name STRING,</span></span></span><br><span class="line"><span class="params"><span class="function">  author STRING,</span></span></span><br><span class="line"><span class="params"><span class="function">  price DECIMAL(<span class="number">8</span>,<span class="number">2</span>)</span></span></span><br><span class="line"><span class="function">) <span class="title">WITH</span> <span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="string">&#x27;connector&#x27;</span> = <span class="string">&#x27;jdbc&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="string">&#x27;url&#x27;</span> = <span class="string">&#x27;jdbc:mysql://hadoop001:3306/mydatabase&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="string">&#x27;username&#x27;</span> = <span class="string">&#x27;root&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="string">&#x27;password&#x27;</span> = <span class="string">&#x27;123456&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="string">&#x27;table-name&#x27;</span> = <span class="string">&#x27;books&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>;</span><br></pre></td></tr></table></figure>

<h3 id="3-输出到ES"><a href="#3-输出到ES" class="headerlink" title="3.输出到ES"></a>3.输出到ES</h3><p>根据ES版本来导入POM依赖</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 6.x --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-elasticsearch6_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 7.x and later versions --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-elasticsearch7_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">CREATE TABLE <span class="title">books</span> <span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">  name STRING,</span></span></span><br><span class="line"><span class="params"><span class="function">  author STRING,</span></span></span><br><span class="line"><span class="params"><span class="function">  price DECIMAL(<span class="number">8</span>,<span class="number">2</span>)</span></span></span><br><span class="line"><span class="function">) <span class="title">WITH</span> <span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="string">&#x27;connector&#x27;</span> = <span class="string">&#x27;elasticsearch-7&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">  <span class="string">&#x27;hosts&#x27;</span> = <span class="string">&#x27;http://localhost:9200&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">  <span class="string">&#x27;index&#x27;</span> = <span class="string">&#x27;books&#x27;</span></span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>;</span><br></pre></td></tr></table></figure>

<h3 id="4-输出到Kafka"><a href="#4-输出到Kafka" class="headerlink" title="4.输出到Kafka"></a>4.输出到Kafka</h3><p>添加pom依赖</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>


<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">CREATE TABLE <span class="title">books</span> <span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">  name STRING,</span></span></span><br><span class="line"><span class="params"><span class="function">  author STRING,</span></span></span><br><span class="line"><span class="params"><span class="function">  price DECIMAL(<span class="number">8</span>,<span class="number">2</span>)</span></span></span><br><span class="line"><span class="function">) <span class="title">WITH</span> <span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">  <span class="string">&#x27;connector&#x27;</span> = <span class="string">&#x27;kafka&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">  <span class="string">&#x27;topic&#x27;</span> = <span class="string">&#x27;books_topic&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">  <span class="string">&#x27;properties.bootstrap.servers&#x27;</span> = <span class="string">&#x27;localhost:9092&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">  <span class="string">&#x27;properties.group.id&#x27;</span> = <span class="string">&#x27;books_group&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">  <span class="string">&#x27;scan.startup.mode&#x27;</span> = <span class="string">&#x27;earliest-offset&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">  <span class="string">&#x27;format&#x27;</span> = <span class="string">&#x27;json&#x27;</span></span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span></span><br></pre></td></tr></table></figure>

<h2 id="SQL优化之查看执行计划"><a href="#SQL优化之查看执行计划" class="headerlink" title="SQL优化之查看执行计划"></a>SQL优化之查看执行计划</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String explain = tableEnv.explainSql(<span class="string">&quot;select name,author,price from books_table where price &gt; 12&quot;</span>);</span><br><span class="line">System.out.println(explain);</span><br></pre></td></tr></table></figure>

<h2 id="Processing-Time-amp-Event-Time"><a href="#Processing-Time-amp-Event-Time" class="headerlink" title="Processing Time &amp; Event Time"></a>Processing Time &amp; Event Time</h2><p>Processing Time 是流数据正在处理的时间，在SQL中指定<code>PROCTIME()</code>来使用。</p>
<p>在有数据乱序的情况下采用事件时间，通常采用数据中的时间戳来做watermark，如下代码便是采用ts做watermark，并允许5秒的乱序。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function">CREATE TABLE <span class="title">books</span> <span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">  name STRING,</span></span></span><br><span class="line"><span class="params"><span class="function">  author STRING,</span></span></span><br><span class="line"><span class="params"><span class="function">  price DECIMAL(<span class="number">8</span>,<span class="number">2</span>)</span>,</span></span><br><span class="line"><span class="function">  proc_time as <span class="title">PROCTIME</span><span class="params">()</span>,</span></span><br><span class="line"><span class="function">  ts <span class="title">TIMESTAMP</span><span class="params">(<span class="number">3</span>)</span>,</span></span><br><span class="line"><span class="function">  WATERMARK FOR ts as ts - INTERVAL &#x27;5&#x27; SECOND</span></span><br><span class="line"><span class="function">) <span class="title">WITH</span> <span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="string">&#x27;connector&#x27;</span> = <span class="string">&#x27;jdbc&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="string">&#x27;url&#x27;</span> = <span class="string">&#x27;jdbc:mysql://hadoop001:3306/mydatabase&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="string">&#x27;username&#x27;</span> = <span class="string">&#x27;root&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="string">&#x27;password&#x27;</span> = <span class="string">&#x27;123456&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">   <span class="string">&#x27;table-name&#x27;</span> = <span class="string">&#x27;books&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>;</span><br></pre></td></tr></table></figure>

<h2 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h2><p>最新版本的一些条件传Expression，可以以$()定义，如$(“10.minutes”)</p>
<p>滚动窗口</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 10分钟一滚动，通过rowtime字段进行，是事件时间窗口，取别名为w</span></span><br><span class="line">.window(Tumble.over(<span class="string">&quot;10.minutes&quot;</span>).on(<span class="string">&quot;rowtime&quot;</span>).as(<span class="string">&quot;w&quot;</span>));</span><br><span class="line">​</span><br><span class="line"><span class="comment">// 10分钟一滚动，通过proctime字段进行，是处理时间窗口，取别名为w</span></span><br><span class="line">.window(Tumble.over(<span class="string">&quot;10.minutes&quot;</span>).on(<span class="string">&quot;proctime&quot;</span>).as(<span class="string">&quot;w&quot;</span>));</span><br><span class="line">​</span><br><span class="line"><span class="comment">// 10条记录一滚动，通过proctime字段进行，取别名为w</span></span><br><span class="line">.window(Tumble.over(<span class="string">&quot;10.rows&quot;</span>).on(<span class="string">&quot;proctime&quot;</span>).as(<span class="string">&quot;w&quot;</span>));</span><br></pre></td></tr></table></figure>

<p>滑动窗口</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 10分钟一个窗口，通过rowtime字段进行，是事件时间窗口，滑动步长为5分钟，取别名为w</span></span><br><span class="line">.window(Slide.over($(<span class="string">&quot;10.minutes&quot;</span>)).every(<span class="string">&quot;5.minutes&quot;</span>).on(<span class="string">&quot;rowtime&quot;</span>).as(<span class="string">&quot;w&quot;</span>));</span><br><span class="line">​</span><br><span class="line"><span class="comment">// 10分钟一个窗口，通过proctime字段进行，是处理时间窗口，滑动步长为5分钟，取别名为w</span></span><br><span class="line">.window(Slide.over(<span class="string">&quot;10.minutes&quot;</span>).every(<span class="string">&quot;5.minutes&quot;</span>).on(<span class="string">&quot;proctime&quot;</span>).as(<span class="string">&quot;w&quot;</span>));</span><br><span class="line">​</span><br><span class="line"><span class="comment">// 10条记录一滚动，通过proctime字段进行，滑动步长为5条记录，取别名为w</span></span><br><span class="line">.window(Slide.over(<span class="string">&quot;10.rows&quot;</span>).every(<span class="string">&quot;5.rows&quot;</span>).on(<span class="string">&quot;proctime&quot;</span>).as(<span class="string">&quot;w&quot;</span>));</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink零基础极速入门</title>
    <url>/2021/06/10/2.bigdata/flink/Flink%E9%9B%B6%E5%9F%BA%E7%A1%80%E6%9E%81%E9%80%9F%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h2 id="Flink简介"><a href="#Flink简介" class="headerlink" title="Flink简介"></a>Flink简介</h2><p>Apache Flink 是一个框架和分布式处理引擎，用于在无边界和有边界数据流上进行有状态的计算。Flink 能在所有常见集群环境中运行，并能以内存速度和任意规模进行计算。</p>
<p>批处理特点是有界，持久，大量，一般做离线计算，如收集一天的数据，然后进行计算。</p>
<p>流处理是无界的，实时进行的，类似于用户的访问日志是会24小时不断产生的。</p>
<p>Flink架构简单来说，就是通过收集各种实时数据，通过数据库，Kafka等中间件发送到Flink流处理程序中，多条流可以并行高效方便的进行分组、合并、过滤等计算，然后得到结果返回到其他中间件系统中进行分析，统计等。</p>
<p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/flink/flink-0.png"></p>
<span id="more"></span>

<h2 id="Flink简单上手体验"><a href="#Flink简单上手体验" class="headerlink" title="Flink简单上手体验"></a>Flink简单上手体验</h2><ol>
<li>先在IDEA中创建一个标准Maven工程，pom加入如下依赖：</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>first-flink-project<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.whoiszxl<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0&lt;/modelVersion</span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>first-flink-project<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">java.version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">java.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.source</span>&gt;</span>$&#123;java.version&#125;<span class="tag">&lt;/<span class="name">maven.compiler.source</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">maven.compiler.target</span>&gt;</span>$&#123;java.version&#125;<span class="tag">&lt;/<span class="name">maven.compiler.target</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">flink.version</span>&gt;</span>1.12.0<span class="tag">&lt;/<span class="name">flink.version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scala.version</span>&gt;</span>2.12<span class="tag">&lt;/<span class="name">scala.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java_$&#123;scala.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>创建一个WordCount批处理程序</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountBatch</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//1. 创建Flink执行环境</span></span><br><span class="line">        ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 直接从本地文件中读取一个文件</span></span><br><span class="line">        DataSet&lt;String&gt; text = env.readTextFile(<span class="string">&quot;/path/to/file&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 按照Tokenizer里的规则进行切分输出，输出的格式是(单词，1)</span></span><br><span class="line">        <span class="comment">// 然后通过下标0的元素，也就是词本身进行分组，分组后将下标2进行计数，达到wordcount的效果</span></span><br><span class="line">        DataSet&lt;Tuple2&lt;String, Integer&gt;&gt; counts =</span><br><span class="line">                text.flatMap(<span class="keyword">new</span> Tokenizer())</span><br><span class="line">                .groupBy(<span class="number">0</span>)</span><br><span class="line">                .sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 输出到控制台</span></span><br><span class="line">        counts.print();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Tokenizer</span> <span class="keyword">implements</span> <span class="title">FlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String value, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; out)</span> </span>&#123;</span><br><span class="line">            <span class="comment">//1. 将读取到的记录按照空格进行分割，并转小写</span></span><br><span class="line">            String[] tokens = value.toLowerCase().split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">            <span class="comment">//2. 将每个单词遍历，转成元组返回出去</span></span><br><span class="line">            <span class="keyword">for</span> (String token : tokens) &#123;</span><br><span class="line">                <span class="keyword">if</span> (token.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    out.collect(<span class="keyword">new</span> Tuple2&lt;String, Integer&gt;(token, <span class="number">1</span>));</span><br><span class="line">                &#125;   </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>创建一个流处理WordCount程序</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountKafka</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String kafkaServers = <span class="string">&quot;hadoop001:9092,hadoop002:9092,hadoop003:9094&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//1. 准备基本数据流执行环境</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//2. 接收kafka数据，并转换成DataStream流</span></span><br><span class="line">        String topic = <span class="string">&quot;wordcount_topic&quot;</span>;</span><br><span class="line">        FlinkKafkaConsumer&lt;String&gt; kafkaSource = <span class="keyword">new</span> FlinkKafkaProducer&lt;String&gt;(kafkaServers, topic, <span class="keyword">new</span> SimpleStringSchema());</span><br><span class="line">        DataStreamSource&lt;String&gt; wcStream = env.addSource(kafkaSource);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//3. 将接收到的Kafka流按照批处理的程序一样进行分组&amp;求和</span></span><br><span class="line">        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; wordCountDataStream = </span><br><span class="line">                wcStream.flatMap(<span class="keyword">new</span> Tokenizer())</span><br><span class="line">                .groupBy(<span class="number">0</span>)</span><br><span class="line">                .sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//4. 输出并执行，流处理程序需要execute一下</span></span><br><span class="line">        wordCountDataStream.print();</span><br><span class="line">        env.execute(<span class="string">&quot;wordCount Kafka task.&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Flink环境搭建"><a href="#Flink环境搭建" class="headerlink" title="Flink环境搭建"></a>Flink环境搭建</h2><p>下载页面：<a href="https://flink.apache.org/downloads.html">https://flink.apache.org/downloads.html</a></p>
<h3 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h3><ol>
<li><p>下载程序到CentOS机器上</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/software</span><br><span class="line">wget https://apache.claz.org/flink/flink-1.13.1/flink-1.13.1-bin-scala_2.11.tgz</span><br></pre></td></tr></table></figure></li>
<li><p>解压到软件安装目录下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 解压并重命名</span></span><br><span class="line">tar xzf flink-*.tgz -C /opt/module</span><br><span class="line">mv /opt/module/flink-* /opt/module/flink</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行，机器需要有JDK环境</span></span><br><span class="line">/opt/module/flink/bin/start-cluster.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出日志检查是否正在运行中</span></span><br><span class="line">tail /opt/module/flink/<span class="built_in">log</span>/flink-*-jobmanager-*.<span class="built_in">log</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出如下日志了说明运行成功</span></span><br><span class="line">INFO ... - Starting web info server <span class="keyword">for</span> JobManager on port 8081</span><br></pre></td></tr></table></figure></li>
<li><p>访问web ui界面进行操作</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">http://ip-addr:8081</span><br></pre></td></tr></table></figure>
<p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/flink/flink-1.png"></p>
</li>
</ol>
<ol start="4">
<li>运行一个内置的示例WordCount<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 运行任务</span></span><br><span class="line">./bin/flink run examples/streaming/WordCount.jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看结果</span></span><br><span class="line">tail <span class="built_in">log</span>/flink-*-taskexecutor-*.out</span><br></pre></td></tr></table></figure></li>
</ol>
<p>或者登录web ui 界面，选择Task Managers查看结果<br><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/flink/flink-2.png"></p>
<h3 id="集群模式"><a href="#集群模式" class="headerlink" title="集群模式"></a>集群模式</h3><ol>
<li><p>编辑conf/flink-conf.yaml文件，将jobmanager.rpc.address: localhost配置修改为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jobmanager.rpc.address: hadoop001</span><br></pre></td></tr></table></figure></li>
<li><p>编辑conf/workers文件，添加如下内容</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hadoop002</span><br><span class="line">hadoop003</span><br></pre></td></tr></table></figure></li>
<li><p>将hadoop001的flink目录拷贝到其他两台机器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -r /opt/module/flink root@hadoop002:/opt/module/</span><br><span class="line">scp -r /opt/module/flink root@hadoop003:/opt/module/</span><br></pre></td></tr></table></figure></li>
<li><p>此时再执行启动脚本就能启动Flink集群环境了</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/opt/module/flink/bin/start-cluster.sh</span><br></pre></td></tr></table></figure>
<p><img src="https://whoiszxl-hexo.oss-cn-beijing.aliyuncs.com/bigdata/flink/flink-3.png"></p>
</li>
</ol>
<h3 id="Flink-on-yarn-模式"><a href="#Flink-on-yarn-模式" class="headerlink" title="Flink on yarn 模式"></a>Flink on yarn 模式</h3><p>此模式依赖Yarn集群来调度Flink程序，此模式应用最多，可充分利用集群资源，复用当前Hadoop集群，可同时执行MR与Flink任务，方便管理维护。</p>
<ol>
<li><p>per job模式<br>每次提交任务都会创建一个新集群，每个任务之间互相独立不影响，任务执行完成后集群自动取消，不占额外资源，资源利用率最大，生产推荐使用。执行如下命令进行启动：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 以per job的模式在yarn上开辟flink集群运行wordcount程序</span></span><br><span class="line">/bin/flink run -m yarn-cluster ./examples/batch/WordCount.jar</span><br></pre></td></tr></table></figure></li>
<li><p>session模式<br>提前初始化Flink集群，此集群会长驻在Yarn集群中，无论有没有任务在运行，提交Flink任务的时候是多个任务提交到此一个Flink集群中。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启动集群 </span></span><br><span class="line"><span class="comment">#-n taskManager数量 </span></span><br><span class="line"><span class="comment">#-s 每个taskManager的slot数量（默认一个slot一个core）</span></span><br><span class="line"><span class="comment">#-jm jobmanager使用内存</span></span><br><span class="line"><span class="comment">#-tm 每个taskmanager的内存</span></span><br><span class="line"><span class="comment">#-nm 集群名字</span></span><br><span class="line"><span class="comment">#-d 后台运行</span></span><br><span class="line">./yarn-session.sh -n 2 -s 2 -jm 1024 -tm 1024 -nm yarn-session-task-cluster -d</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行一个Flink任务进行测试</span></span><br><span class="line">./bin/flink run ./examples/batch/WordCount.jar -input hdfs://hadoop001:8020/input/* -output hdfs://hadoop001:8020/output</span><br></pre></td></tr></table></figure></li>
<li><p>运行中的问题</p>
</li>
</ol>
<p>a. 报如下异常：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java.lang.IllegalStateException: No Executor found. Please make sure to export the HADOOP_CLASSPATH environment variable or have hadoop in your classpath. For more information refer to the &quot;Deployment&quot; section of the official Apache Flink documentation.</span><br></pre></td></tr></table></figure>

<p>参考官方文档：<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/hadoop.html">https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/deployment/hadoop.html</a>, 执行如下命令或者在<code>./bin/flink</code>文件中增加。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_CLASSPATH=`hadoop classpath`</span><br></pre></td></tr></table></figure>

<p>b. 提示内存不够</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Maximum Memory: 1024MB Requested: 1600MB. Please check the &#x27;yarn.scheduler.maximum-allocation-mb&#x27; and the &#x27;yarn.nodemanager.resource.memory-mb&#x27; configuration values</span><br></pre></td></tr></table></figure>
<p>需要调大YARN的<code>yarn.scheduler.maximum-allocation-mb</code>和<code>yarn.nodemanager.resource.memory-mb</code>配置，再重启集群。</p>
<p>c. 提示没有HDFS权限</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=root, access=WRITE, inode=&quot;/user&quot;:hdfs:supergroup:drwxr-xr-x</span><br></pre></td></tr></table></figure>
<p>把HDFS的<code>dfs.permission</code>权限检查关闭就完事了，但是这样会有不可控的风险。可以在HDFS中指定特定的用户进行写操作。</p>
<h2 id="Flink-API"><a href="#Flink-API" class="headerlink" title="Flink API"></a>Flink API</h2><p>Flink目前有四种API，分别如下：</p>
<ol>
<li>低级API: 对时间和状态最细粒度控制，易用性差，适合处理复杂事件。</li>
<li>核心API: DataSet和DataStream相关API，是对低级API的封装，简单易用应用广泛。</li>
<li>Table API: 将数据流模拟成表的结构，可以通过SELECT,JOIN等方法直接操作流。</li>
<li>SQL API: 可以直接用SQL查询模拟成表的数据流。</li>
</ol>
<h3 id="Environment-环境上下文"><a href="#Environment-环境上下文" class="headerlink" title="Environment 环境上下文"></a>Environment 环境上下文</h3><ol>
<li><p>getExecutionEnvironment 根据当前执行环境是本地环境还是集群环境创建对应的执行上下文环境对象。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br></pre></td></tr></table></figure></li>
<li><p>创建流执行上下文环境</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br></pre></td></tr></table></figure></li>
<li><p>创建本地执行上下文环境，并指定并行度</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LocalStreamEnvironment env = StreamExecutionEnvironment.createLocalEnvironment(4);</span><br></pre></td></tr></table></figure></li>
<li><p>获取远程集群执行环境，并提交jar包</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.createRemoteEnvironment(<span class="string">&quot;hadoop001&quot;</span>, <span class="number">6123</span>, <span class="string">&quot;C://WordCount.jar&quot;</span>);</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="DataSource-数据源"><a href="#DataSource-数据源" class="headerlink" title="DataSource 数据源"></a>DataSource 数据源</h3><ol>
<li><p>从集合读取数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataStream&lt;Integer&gt; nums = env.fromElements(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>);</span><br><span class="line">DataStream&lt;String&gt; nums2 = env.fromCollection(Arrays.asList(<span class="string">&quot;xiaozhou&quot;</span>, <span class="string">&quot;hello&quot;</span>));</span><br></pre></td></tr></table></figure></li>
<li><p>从文件读取数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataStream&lt;String&gt; fileDs = env.readTextFile(<span class="string">&quot;/opt/hello.txt&quot;</span>);</span><br></pre></td></tr></table></figure></li>
<li><p>从socket中读取</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">DataStream&lt;String&gt; socketDs = env.socketTextStream(&quot;localhost&quot;, &quot;1000&quot;);</span><br></pre></td></tr></table></figure></li>
<li><p>从Kafka中读取</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">properties.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId);</span><br><span class="line">properties.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaServers);</span><br><span class="line">FlinkKafkaConsumer&lt;String&gt; kafkaConsumer = <span class="keyword">new</span> FlinkKafkaConsumer&lt;String&gt;(topic, <span class="keyword">new</span> SimpleStringSchema(), properties);</span><br><span class="line">DataStream&lt;String&gt; kafkaDs = env.addSource(kafkaConsumer);</span><br></pre></td></tr></table></figure></li>
<li><p>自定义DataSource</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SayHello</span> <span class="keyword">implements</span> <span class="title">SourceFunction</span>&lt;<span class="title">String</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> running = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;String&gt; ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(running) &#123;</span><br><span class="line">            ctx.collect(<span class="string">&quot;hello &quot;</span> + i);</span><br><span class="line">            Thread.sleep(<span class="number">1000L</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cancel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.running = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="Transform-转换算子"><a href="#Transform-转换算子" class="headerlink" title="Transform 转换算子"></a>Transform 转换算子</h3><ol>
<li><p>map，从一个数据流转换为另一个流，比如从String转为Student，每条输入对应一条输出。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">stuDs.map(<span class="keyword">new</span> MapFunction&lt;String, Student&gt;() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Student <span class="title">map</span><span class="params">(String value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> JSON.parseObject(value, Student.class);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">//也可以使用Lambda方式</span></span><br><span class="line">stuDs.map(value -&gt; JSON.parseObject(value, Student.class));</span><br></pre></td></tr></table></figure></li>
<li><p>filter，过滤器，过滤不需要的数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataStream&lt;String&gt; filterDs = strDs.filter(<span class="keyword">new</span> FilterFunction&lt;String&gt;() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(String value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//过滤字符串长度不为2的</span></span><br><span class="line">        <span class="keyword">return</span> value.length() == <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></li>
<li><p>flatMap，与map类似，但是flatMap的输出可以是0 ~ 任意个，可以在实现方法中定义自己的逻辑。实际上flatMap同时具有map和filter的功能，没有完全替换是因为map和filter的语义上更明确，可读性更高。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">    env.setParallelism(<span class="number">1</span>);</span><br><span class="line">    DataSource&lt;String&gt; dataSource = env.fromElements(<span class="string">&quot;hello xiaozhou&quot;</span>, <span class="string">&quot;hello world&quot;</span>, <span class="string">&quot;hello xiaozhou&quot;</span>);</span><br><span class="line">    FlatMapOperator&lt;String, String&gt; flatMapOperator = dataSource.flatMap(<span class="keyword">new</span> FlatMapFunction&lt;String, String&gt;() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String s, Collector&lt;String&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            String[] strs = s.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">            <span class="keyword">for</span> (String str : strs) &#123;</span><br><span class="line">                <span class="keyword">if</span>(!str.equals(<span class="string">&quot;hello&quot;</span>)) &#123;</span><br><span class="line">                    collector.collect(str);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    flatMapOperator.print();</span><br><span class="line">    env.execute();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>keyBy，分组操作，将单个DataStream转换为多个不相交的KeyedStream流，每个分区包含具有相同key的元素，内部以Hash实现。可以通过<code>sum(), min(), max(), minBy(), maxBy()</code>进行聚合计算。</p>
</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//通过json对象中的省份参数进行分组</span></span><br><span class="line">KeyedStream&lt;JSONObject, String&gt; keyByStream = jsonObjectDS.keyBy(data -&gt; data.getJSONObject(<span class="string">&quot;province&quot;</span>));</span><br></pre></td></tr></table></figure>

<ol start="5">
<li><p>Reduce聚合操作，将KeyedStream -&gt; DataStream，对每个key分区进行合并，并将所有分区数据输出</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//对将省份分组数据进行聚合，将销售额进行累加并返回一条整流</span></span><br><span class="line">SingleOutputStreamOperator&lt;ProvinceSaleData&gt; reduce = keyedDs.reduce(<span class="keyword">new</span> ReduceFunction&lt;ProvinceSaleData&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProvinceSaleData <span class="title">reduce</span><span class="params">(ProvinceSaleData one, ProvinceSaleData two)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        one.setAmount(one.getAmount() + two.getAmount());</span><br><span class="line">        <span class="keyword">return</span> one;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></li>
<li><p>connect连接操作，连接两个保持他们类型的数据流到ConnectedStream中，两个流的数据类型可以不同。</p>
</li>
<li><p>union操作，合并多个流，新的流会包含所有流中的数据，合并的流的类型必须一致。</p>
</li>
<li><p>coMap和coFlatMap，在ConnectedStream中使用，类似map和flatMap操作。</p>
</li>
</ol>
<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="UDF函数"><a href="#UDF函数" class="headerlink" title="UDF函数"></a>UDF函数</h3><p>自定义函数，可以按照自己的需求更加细粒度的控制流</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataStream&lt;String&gt; flinkTweets = tweets.filter(<span class="keyword">new</span> FlinkFilter(<span class="string">&quot;flink&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//过滤出包含Flink单词的记录UDF函数</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FlinkFilter</span> <span class="keyword">implements</span> <span class="title">FilterFunction</span>&lt;<span class="title">String</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String keyWord;</span><br><span class="line">    KeyWordFilter(String keyWord) &#123; <span class="keyword">this</span>.keyWord = keyWord; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(String value)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> value.contains(keyword);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataStream&lt;String&gt; flinkTweets = tweets.filter(tweet -&gt; tweet.contains(<span class="string">&quot;flink&quot;</span>) );</span><br></pre></td></tr></table></figure>

<h3 id="富函数"><a href="#富函数" class="headerlink" title="富函数"></a>富函数</h3><p>所有Flink函数类都有对应的富函数版本，富函数功能增强了，可以拿到运行的上下文环境，并拥有open，close，getRuntimeContext的生命周期。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyRichFilterFunction</span> <span class="keyword">extends</span> <span class="title">RichFilterFunction</span>&lt;<span class="title">String</span>&gt; </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">//进行过滤操作</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.open(parameters);</span><br><span class="line">        <span class="comment">//进行初始化操作，比如说连接数据库，开启JDBC</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.close();</span><br><span class="line">        <span class="comment">//进行关闭操作，比如说断开数据库连接</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Sink-输出操作"><a href="#Sink-输出操作" class="headerlink" title="Sink 输出操作"></a>Sink 输出操作</h2><p>sink可以将计算的数据输入到Flume，Redis，ES，Kafka等中间件中，再进行下一步计算。</p>
<ol>
<li>Kafka操作</li>
</ol>
<p>先添加pom依赖</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-kafka-0.11_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>代码调用</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ds.addSink(<span class="keyword">new</span> FlinkKafkaProducer&lt;String&gt;(kafkaServers, topic, <span class="keyword">new</span> SimpleStringSchema()));</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>Redis操作<br>先添加pom依赖<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.bahir<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-redis_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<p>定义一个Redis的mapper类，定义保存到Redis时调用的命令</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyRedisMapper</span> <span class="keyword">implements</span> <span class="title">RedisMapper</span>&lt;<span class="title">Student</span>&gt;</span>&#123;</span><br><span class="line">    <span class="comment">//定义命令，为hash存储,key为allstudents</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> RedisCommandDescription <span class="title">getCommandDescription</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> RedisCommandDescription(RedisCommand.HSET, <span class="string">&quot;allstudents&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//用对象的id当hashkey</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getKeyFromData</span><span class="params">(Student student)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> student.getId();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//用对象姓名作hashvalue</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getValueFromData</span><span class="params">(Student student)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> student.getName();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>代码调用</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//定义Jedis的连接配置</span></span><br><span class="line">FlinkJedisPoolConfig config = <span class="keyword">new</span> FlinkJedisPoolConfig.Builder().setHost(<span class="string">&quot;hadoop001&quot;</span>).setPort(<span class="number">6379</span>).build();</span><br><span class="line"></span><br><span class="line"><span class="comment">//添加到sink</span></span><br><span class="line">dataStream.addSink(<span class="keyword">new</span> RedisSink&lt;Student&gt;(config, <span class="keyword">new</span> MyRedisMapper()));</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>ES操作</li>
</ol>
<p>添加pom依赖</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-connector-elasticsearch6_2.12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.10.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>定义一个ES的sink方法</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyEsSinkFunction</span> <span class="keyword">implements</span> <span class="title">ElasticsearchSinkFunction</span>&lt;<span class="title">Student</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(Student student, RuntimeContext ctx, RequestIndexer indexer)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//将对象转map后存入es</span></span><br><span class="line">        HashMap&lt;String, String&gt; dataSource = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        dataSource.put(<span class="string">&quot;id&quot;</span>, student.getId());</span><br><span class="line">        dataSource.put(<span class="string">&quot;name&quot;</span>, student.getName().toString());</span><br><span class="line">        IndexRequest indexRequest = Requests.indexRequest()</span><br><span class="line">                .index(<span class="string">&quot;school&quot;</span>)</span><br><span class="line">                .type(<span class="string">&quot;student&quot;</span>)</span><br><span class="line">                .source(dataSource);</span><br><span class="line">        indexer.add(indexRequest);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>调用</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//配置ES http连接</span></span><br><span class="line">ArrayList&lt;HttpHost&gt; httpHosts = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">httpHosts.add(<span class="keyword">new</span> HttpHost(<span class="string">&quot;localhost&quot;</span>, <span class="number">9200</span>));</span><br><span class="line">dataStream.addSink(<span class="keyword">new</span> ElasticsearchSink.Builder&lt;SensorReading&gt;(httpHosts, <span class="keyword">new</span> MyEsSinkFunction()).build());</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>自定义JDBC Sink</li>
</ol>
<p>添加pom<br>``pom<br><dependency><br>    <groupId>mysql</groupId><br>    <artifactId>mysql-connector-java</artifactId><br>    <version>5.1.44</version><br></dependency></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">添加MyJDBCSink</span><br><span class="line">```java</span><br><span class="line">public class SinkToMySQL extends RichSinkFunction&lt;Student&gt; &#123;</span><br><span class="line">    PreparedStatement ps;</span><br><span class="line">    private Connection connection;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void open(Configuration parameters) throws Exception &#123;</span><br><span class="line">        super.open(parameters);</span><br><span class="line">        //打开连接，只会执行一次，所以在此处初始化连接最合适</span><br><span class="line">        connection = getConnection();</span><br><span class="line">        String sql = &quot;insert into student(id, name, password) values(?, ?, ?);&quot;;</span><br><span class="line">        ps = this.connection.prepareStatement(sql);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void close() throws Exception &#123;</span><br><span class="line">        super.close();</span><br><span class="line">        //关闭连接和释放资源</span><br><span class="line">        if (connection != null) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">        if (ps != null) &#123;</span><br><span class="line">            ps.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void invoke(Student value, Context context) throws Exception &#123;</span><br><span class="line">        //每条数据插入都要执行一次invoke</span><br><span class="line">        ps.setInt(1, value.getId());</span><br><span class="line">        ps.setString(2, value.getName());</span><br><span class="line">        ps.setString(3, value.getPassword());</span><br><span class="line">        ps.executeUpdate();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private static Connection getConnection() &#123;</span><br><span class="line">        Connection conn = null;</span><br><span class="line">        try &#123;</span><br><span class="line">            Class.forName(&quot;com.mysql.jdbc.Driver&quot;);</span><br><span class="line">            conn = DriverManager.getConnection(</span><br><span class="line">                    &quot;jdbc:mysql://localhost:3306/flink?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false&quot;,</span><br><span class="line">                    &quot;root&quot;,</span><br><span class="line">                    &quot;123456&quot;);</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            log.error(e);</span><br><span class="line">        &#125;</span><br><span class="line">        return conn;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
  <entry>
    <title>Flink高级API极速入门</title>
    <url>/2021/06/10/2.bigdata/flink/Flink%E9%AB%98%E7%BA%A7API%E6%9E%81%E9%80%9F%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在学习完零基础入门后，就能够学会如何创建流，读取数据，如何使用算子进行数据处理，如何将计算结果输出到MySQL，Redis等地方了。但是因为在数据传输过程中会出现很多各种各样的情况，比如说上报的数据时间是乱序的，这个就需要用到Window窗口了。</p>
<h3 id="Window概念介绍"><a href="#Window概念介绍" class="headerlink" title="Window概念介绍"></a>Window概念介绍</h3><p>Window本质上是流处理与批处理的桥梁，可以让你在无限流里创建有限流进行操作，比如说可以在源源不断的订单数据中计算5分钟内的销售额，计算最近100个订单都是哪个地区的。</p>
<p>所以此时通过这个例子，我们就能发现Window是分两种，一种是<code>CountWindow</code>，按照指定的数据条数来创建Window，就是上面所说的通过100个订单来统计地区，另一种是<code>TimeWindow</code>,按照指定的时间来生成窗口。</p>
<span id="more"></span>

<p><code>TimeWindow</code>其实也分了三种，一种滚动窗口(Tumbling Window)，一种滑动窗口(Sliding Window)，还有一种会话窗口(Session Window)。</p>
<ol>
<li>滚动窗口：窗口数据没有重叠，比如说每五分钟统计一次，那么一小时就有12个不重叠的窗口创建。</li>
<li>滑动窗口：窗口数据是可能存在重叠的，比如说窗口是五分钟的范围，然后滑动参数是3分钟，当第一个窗口运行到三分钟的时候，第二个窗口就启动了，所以此时第一个窗口的后两分钟和第二个窗口的前两分钟是重叠的。</li>
<li>会话窗口：类似于web的session，当一段时间没有收到新数据的时候就会生成新的窗口。</li>
</ol>
<h2 id="Window-API"><a href="#Window-API" class="headerlink" title="Window API"></a>Window API</h2><h3 id="滚动窗口"><a href="#滚动窗口" class="headerlink" title="滚动窗口"></a>滚动窗口</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//desc: 每10秒统计一次窗口里的最小值</span></span><br><span class="line"><span class="comment">//1. 对2元素的元组的第一个进行分组</span></span><br><span class="line"><span class="comment">//2. 然后创建一个10秒长的滚动窗口，一分钟6个窗口</span></span><br><span class="line"><span class="comment">//3. 对元组第二个元素进行取最小值操作</span></span><br><span class="line">ds.keyBy(data -&gt; data.f0)</span><br><span class="line">        .window(TumblingEventTimeWindows.of(Time.seconds(<span class="number">10</span>)))</span><br><span class="line">        .minBy(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//desc: 每隔10秒开启一个窗口，统计之后60秒里的最小值</span></span><br><span class="line"><span class="comment">//1. 对2元素的元组的第一个进行分组</span></span><br><span class="line"><span class="comment">//2. 然后创建一个60秒长的滑动窗口，每10秒创建一次,如果窗口和滑动间隔都是同样的话，那就是一个滚动窗口了</span></span><br><span class="line"><span class="comment">//3. 对元组第二个元素进行取最小值操作</span></span><br><span class="line">ds.keyBy(data -&gt; data.f0)</span><br><span class="line">        .window(SlidingEventTimeWindows.of(Time.seconds(<span class="number">60</span>), Time.seconds(<span class="number">10</span>)))</span><br><span class="line">        .minBy(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<h3 id="计数窗口"><a href="#计数窗口" class="headerlink" title="计数窗口"></a>计数窗口</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//desc 滚动方式每一百次求一次和</span></span><br><span class="line">ds.keyBy(data -&gt; data.f0)</span><br><span class="line">        .countWindow(<span class="number">100</span>)</span><br><span class="line">        .sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//desc 滑动方式每10次创建一个窗口，每个窗口容纳100次。</span></span><br><span class="line">ds.keyBy(data -&gt; data.f0)</span><br><span class="line">        .countWindow(<span class="number">100</span>, <span class="number">10</span>)</span><br><span class="line">        .sum(<span class="number">1</span>);</span><br></pre></td></tr></table></figure>

<h2 id="Window-Function"><a href="#Window-Function" class="headerlink" title="Window Function"></a>Window Function</h2><p>常用增量聚合函数有：ReduceFcuntion，AggregateFunction，每有数据来就进行计算，保持一个简单的状态。</p>
<p>全窗口函数有：ProcessWindowFunction。先收集窗口中所有数据，等到计算的时候再统一遍历处理。</p>
<h2 id="Flink的多种时间状态"><a href="#Flink的多种时间状态" class="headerlink" title="Flink的多种时间状态"></a>Flink的多种时间状态</h2><ol>
<li>每条记录上传时，比如在APP发生了一次点击商详的事件，那么在点击的那一刻就会创建一个<code>Event Time</code>，就是这个事件时间。(对于统计与时间有强关系的流，事件时间则更加合适，大部分的流计算都用此时间。)</li>
<li>当此次点击商详时间的日志上传到SpringBoot项目里，再发送到了Kafka，Flink消费到Kafka里的日志时，就会产生一个<code>Ingestion Time</code>，这个就是数据进入Flink的摄入时间。</li>
<li>在算子执行的过程中，就会产生一个<code>Processing Time</code>，是机器的本地时间，无配置其他时间则默认此时间。</li>
</ol>
<h2 id="Watermark"><a href="#Watermark" class="headerlink" title="Watermark"></a>Watermark</h2><p>在我们点击商品详情的时候，消息日志从APP客户端到Web端，再到Kafka消息队列，再到Flink中，是需要有一定时间的。虽然基本上每次点击都是有顺序的，但是不能排除存在因为网络延迟，中间件宕机等缘故，而导致乱序，导致点击加购的事件会发生在进入商详之前。</p>
<p>此时就需要一个watermark机制的引入来处理乱序事件，watermark是一个告诉Flink消息能够延迟多久的机制，比如说10秒的窗口，水位线为2秒，那么此时Flink就会等到12秒的时候才关闭窗口进行计算。</p>
<h3 id="引入方式"><a href="#引入方式" class="headerlink" title="引入方式"></a>引入方式</h3><p>比如说接收了一个订单信息流，此时指定一个乱序时间戳提取器，指定提取的事件时间为创建时间，并且此时间必须是毫秒数。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ds.assignTimestampsAndWatermarks(<span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor&lt;OrderEntity&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(OrderEntity element)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//指定数据源中的时间戳，毫秒级时间戳</span></span><br><span class="line">        <span class="keyword">return</span> element.getCreateTime();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h2 id="底层API-ProcessFunction"><a href="#底层API-ProcessFunction" class="headerlink" title="底层API ProcessFunction"></a>底层API ProcessFunction</h2><p>只有底层API才能够访问事件的时间戳和水位线和注册定时事件，还可以输出特定的事件如超时事件。Flink有如下8个Process Function：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. ProcessFunction</span><br><span class="line">2. KeyedProcessFunction</span><br><span class="line">3. CoProcessFunction</span><br><span class="line">4. ProcessJoinFunction</span><br><span class="line">5. BroadcastProcessFunction</span><br><span class="line">6. KeyedBroadcastProcessFunction</span><br><span class="line">7. ProcessWindowFunction</span><br><span class="line">8. ProcessAllWindowFunction</span><br></pre></td></tr></table></figure>

<h3 id="KeyedProcessFunction简介"><a href="#KeyedProcessFunction简介" class="headerlink" title="KeyedProcessFunction简介"></a>KeyedProcessFunction简介</h3><p>此函数用来操作KeyedStream，KeyedProcessFunction会去处理流中的每个元素，输出为0,1,或多个元素，在具有基础的open(),close(),getRuntimeContext()等方法外，还有额外的两个方法：processElement, onTimer。</p>
<p>代码实现：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//todo </span></span><br></pre></td></tr></table></figure>

<h2 id="SideOutput"><a href="#SideOutput" class="headerlink" title="SideOutput"></a>SideOutput</h2><p>侧输出流可以产生多条数据类型不一样的流，与split切分类似，只是split切分的流类型是一样的。</p>
<p>代码实现，实现按国家输出侧流</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1. 定义CN标签和USA标签</span></span><br><span class="line">OutputTag&lt;JSONObject&gt; cnTag = <span class="keyword">new</span> OutputTag&lt;JSONObject&gt;(<span class="string">&quot;cn&quot;</span>)&#123;&#125;;</span><br><span class="line">OutputTag&lt;JSONObject&gt; usaTag = <span class="keyword">new</span> OutputTag&lt;JSONObject&gt;(<span class="string">&quot;usa&quot;</span>)&#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2. 通过process方法对每个元素进行处理，通过country判断进行分流</span></span><br><span class="line">SingleOutputStreamOperator&lt;JSONObject&gt; otherCountry = jsonObjDS.process(<span class="keyword">new</span> ProcessFunction&lt;JSONObject, JSONObject() &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(JSONObject value, Context ctx, Collector&lt;JSONObject&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (value.getString(<span class="string">&quot;country&quot;</span>).equals(<span class="string">&quot;cn&quot;</span>)) &#123;</span><br><span class="line">            ctx.output(cnTag, value);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (value.getString(<span class="string">&quot;country&quot;</span>).equals(<span class="string">&quot;usa&quot;</span>)) &#123;</span><br><span class="line">            ctx.output(usaTag, value);</span><br><span class="line">        &#125;</span><br><span class="line">        out.collect(value);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">//3. 从主流中通过标签获取到侧流</span></span><br><span class="line">DataStream&lt;JSONObject&gt; cnSideOutput = otherCountry.getSideOutput(cnTag);</span><br><span class="line">DataStream&lt;JSONObject&gt; usaSideOutput = otherCountry.getSideOutput(usaTag);</span><br><span class="line"></span><br><span class="line"><span class="comment">//4. 输出</span></span><br><span class="line">otherCountry.print(<span class="string">&quot;other::&quot;</span>);</span><br><span class="line">cnSideOutput.print(<span class="string">&quot;cn::&quot;</span>);</span><br><span class="line">usaSideOutput.print(<span class="string">&quot;usa::&quot;</span>);</span><br></pre></td></tr></table></figure>

<h2 id="CoProcessFunction"><a href="#CoProcessFunction" class="headerlink" title="CoProcessFunction"></a>CoProcessFunction</h2><p>两条输入流可以使用此方法来操作，使用processElement1()和processElement2()可以分别操作两条流，这两个方法都可以使用Context对象来调用，context可以访问事件数据，定时器时间戳，TimerService和SideOutputs。CoProcessFunction也提供了onTimer()。</p>
<h2 id="状态编程和容错机制"><a href="#状态编程和容错机制" class="headerlink" title="状态编程和容错机制"></a>状态编程和容错机制</h2><p>流式计算分为有状态和无状态，无状态接收记录，并直接计算直接输出记录，有状态则会根据输入记录来维护中间状态，并通过输入记录与状态值来进行计算输出。</p>
<h3 id="有状态算子"><a href="#有状态算子" class="headerlink" title="有状态算子"></a>有状态算子</h3><p>在Flink中有两种类型的算子，分别是：算子状态和键控状态。</p>
<p>算子状态的作用范围限定为算子任务，同一并行任务处理的所有数据都可以访问到相同的状态，对同一个任务而言是共享的。算子状态有三种基本数据结构。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 列表状态（List state）</span><br><span class="line">将状态表示为一组数据的列表。</span><br><span class="line"></span><br><span class="line">2. 联合列表状态（Union list state）</span><br><span class="line">状态表示为数据的列表。与常规列表状态的区别在于在发生故障时，或者从保存点（savepoint）启动应用程序时如何恢复。</span><br><span class="line"></span><br><span class="line">3. 广播状态（Broadcast state）</span><br><span class="line">如果一个算子有多项任务且每项任务状态都相同，此情况最适应用广播状态</span><br></pre></td></tr></table></figure>

<p>键控状态是根据数据流中定义的键来维护和访问的，Flink为每个键值维护一个状态实例，并将键相同的数据都分区到同一个算子任务里，这个任务会维护和处理这个key的对应状态，当任务处理一条数据时，它会自动将状态的访问范围限定为当前数据的key。因此，<code>具有相同的key的所有数据都会访问相同的状态</code>。就相当于对数据分了组，并给每个组都一个状态。</p>
<h2 id="Checkpoint-检查点"><a href="#Checkpoint-检查点" class="headerlink" title="Checkpoint 检查点"></a>Checkpoint 检查点</h2><p>保证exactly-once，就需要使用检查点在出现故障（网络故障，代码bug等）时将系统重置回到正确状态。检查点可以根据配置周期性地生成快照，将这些快照存储到内存，rocksdb或者HDFS上，一旦出现错误了，那么就会有选择的从快照中进行恢复。</p>
<p>通过如下代码可以开启并配置：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1.创建基础的流执行上下文环境，并配置并行度为4</span></span><br><span class="line">StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setParallelism(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//2.开启检查点功能，并配置检查点的创建周期为5秒，设置模式为EXACTLY_ONCE，这也是默认的模式。</span></span><br><span class="line">env.enableCheckpointing(<span class="number">5000</span>, CheckpointingMode.EXACTLY_ONCE);</span><br><span class="line"></span><br><span class="line"><span class="comment">//3.配置检查点的超时时间是20秒，检查点必须在20秒内完成，或者被丢弃。</span></span><br><span class="line">env.getCheckpointConfig().setCheckpointTimeout(<span class="number">20</span> * <span class="number">1000</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//4.配置最大的并发操作是1，同一时间只允许1个检查点执行。</span></span><br><span class="line">env.getCheckpointConfig().setMaxConcurrentCheckpoints(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//5.配置持久化端为HDFS</span></span><br><span class="line">env.setStateBackend(<span class="keyword">new</span> FsStateBackend(<span class="string">&quot;hdfs://hadoop001:9820/project_name/flink/checkpoint&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">//6. 其他配置</span></span><br><span class="line"><span class="comment">//......</span></span><br></pre></td></tr></table></figure>

<h3 id="StateBackend"><a href="#StateBackend" class="headerlink" title="StateBackend"></a>StateBackend</h3><ol>
<li><p>MemoryStateBackend：默认状态下，State状态会保存在TaskManager的堆内存中，Checkpoint检查点会保存到JobManager的内存中，内存是不稳定的，一旦宕机则会丢失，所以在生产环境下是不建议使用的。</p>
</li>
<li><p>FsStateBackend：State数据保存在TaskManager内存中，执行Checkpoint时，会把State的快照数据保存到配置的文件系统中，可以用本地文件，或者HDFS。</p>
</li>
<li><p>RocksDBStateBackend：在本地文件中维护状态，State状态直接写入本地的RocksDB中，同时需要配置一个远端的文件系统地址，一般是使用HDFS，在进行Checkpoint的时候，会把本地的数据直接复制到远程的HDFS中，故障切换的时候直接从远端的文件系统直接恢复数据到本地。RocksDB使用本地磁盘存储，便无内存的大小限制，又能存储数据到远程文件系统中，但是RocksDB的序列化反序列化存储会有一点性能影响，推荐此方式在生产中使用。</p>
</li>
</ol>
<p>修改存储方式的方法有两种，一种是代码修改，代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//修改为hdfs的存储方式</span></span><br><span class="line">env.setStateBackend(<span class="keyword">new</span> FsStateBackend(<span class="string">&quot;hdfs://hadoop001:9820/project_name/flink/checkpoints&quot;</span>));</span><br></pre></td></tr></table></figure>

<p>在使用RocksDBStateBackend的时候，是需要在pom中引入第三方依赖，然后再在代码中引用：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-statebackend-rocksdb_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.6.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">env.setStateBackend(<span class="keyword">new</span> RocksDBStateBackend(<span class="string">&quot;hdfs://hadoop001:9820/project_name/flink/checkpoints&quot;</span>, <span class="keyword">true</span>));</span><br></pre></td></tr></table></figure>

<p>另一种是修改flink-conf.yml，修改的参数如下：</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 文件系统</span></span><br><span class="line"><span class="attr">state.backend:</span> <span class="string">filesystem</span></span><br><span class="line"><span class="attr">state.checkpoints.dir:</span> <span class="string">hdfs://namenode:9000/flink/checkpoints</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># rocksdb</span></span><br><span class="line"><span class="attr">state.backend:</span> <span class="string">rocksdb</span></span><br><span class="line"><span class="attr">state.backend.incremental:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">state.checkpoints.dir:</span> <span class="string">hdfs://namenode:9000/flink/checkpoints</span></span><br></pre></td></tr></table></figure>

<h3 id="Restart-Strategy"><a href="#Restart-Strategy" class="headerlink" title="Restart Strategy"></a>Restart Strategy</h3><p>Flink支持的重启策略有三种，一种是固定间隔，一种是失败率，还有一种是无重启，没有启动Checkpoint，则使用无重启策略，如果启用了Checkpoint默认策略就是固定间隔策略，允许尝试重启的次数是Integer.MAX_VALUE次。</p>
<ol>
<li>重启策略</li>
</ol>
<p>通过flink-conf.yaml修改：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">restart-strategy:</span> <span class="string">fixed-delay</span></span><br><span class="line"><span class="attr">restart-strategy.fixed-delay.attempts:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">restart-strategy.fixed-delay.delay:</span> <span class="number">10</span> <span class="string">s</span></span><br></pre></td></tr></table></figure>

<p>代码中配置：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">env.setRestartStrategy(RestartStrategies.fixedDelayRestart(</span><br><span class="line">    Time.of(<span class="number">10</span>, TimeUnit.SECONDS)</span><br><span class="line">));</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>失败率<br>通过flink-conf.yaml修改：<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">restart-strategy:</span> <span class="string">failure-rate</span></span><br><span class="line"><span class="attr">restart-strategy.failure-rate.max-failures-per-interval:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">restart-strategy.failure-rate.failure-rate-interval:</span> <span class="number">5</span> <span class="string">min</span></span><br><span class="line"><span class="attr">restart-strategy.failure-rate.delay:</span> <span class="number">10</span> <span class="string">s</span></span><br></pre></td></tr></table></figure></li>
</ol>
<p>代码中配置：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setRestartStrategy(RestartStrategies.failureRateRestart(</span><br><span class="line">    <span class="number">3</span>, <span class="comment">// 最大的失败次数</span></span><br><span class="line">    Time.of(<span class="number">5</span>, TimeUnit.MINUTES), <span class="comment">//衡量失败次数的时间段</span></span><br><span class="line">    Time.of(<span class="number">10</span>, TimeUnit.SECONDS) <span class="comment">//间隔</span></span><br><span class="line">));</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>无重启<br>通过flink-conf.yaml修改：<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">restart-strategy:</span> <span class="string">none</span></span><br></pre></td></tr></table></figure></li>
</ol>
<p>代码配置：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">env.setRestartStrategy(RestartStrategies.noRestart());</span><br></pre></td></tr></table></figure>

<h2 id="Savepoint-保存点"><a href="#Savepoint-保存点" class="headerlink" title="Savepoint 保存点"></a>Savepoint 保存点</h2><p>Savepoint是某个时间点程序状态的全局镜像，之后程序升级或者修改配置等情况下还能从保存的状态继续启动恢复。一般存在HDFS上，用户主动触发，是指向Checkpoint的指针，不会过期。</p>
<p>一般建议程序通过uid()方法给算子赋ID，这个配置的ID将确定算子执行的状态范围，只要ID未变就能从保存点恢复程序。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DataStreamSource&lt;String&gt; jsonStrStream = env.addSource(kafkaSource);</span><br><span class="line">jsonStrStream.uid(<span class="string">&quot;kafka-source-id&quot;</span>);</span><br><span class="line"></span><br><span class="line">DataStream&lt;JSONObject&gt; jsonObjDS = jsonStrStream.map(<span class="keyword">new</span> MapFunction&lt;String, JSONObject&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> JSONObject <span class="title">map</span><span class="params">(String s)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> JSON.parseObject(s);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;).uid(<span class="string">&quot;to-json-obj-id&quot;</span>);</span><br><span class="line">        </span><br></pre></td></tr></table></figure>

<h3 id="如何开启Savepoint功能"><a href="#如何开启Savepoint功能" class="headerlink" title="如何开启Savepoint功能"></a>如何开启Savepoint功能</h3><p>修改flink-conf.yaml配置，这样在手动执行命令的时候可以不用指定保存路径</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">state.savepoints.dir:</span> <span class="string">hdfs://hadoop001:8120/project_name/flink/savepoints</span></span><br></pre></td></tr></table></figure>

<p>如何触发一个savepoint</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 手动触发保存</span></span><br><span class="line">flink savepoint jobId [targetDir] [-yid yarnAppId]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用cancel的时候触发savepoint</span></span><br><span class="line">flink cancel -s [targetDir] jobId [-yid yarnAppId]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从指定的savepoint启动job</span></span><br><span class="line">flink run -s savepointPath [runArgs]</span><br></pre></td></tr></table></figure>




]]></content>
      <categories>
        <category>大数据</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Flink</tag>
      </tags>
  </entry>
</search>
